%===============================================================================
\section{Modelos para sistemas não lineares}
\label{sec:nl_models}
%===============================================================================
% ideia aqui é colocar uma pequena introdução sobre modelos.. no mesmo estilo
% que foi para sistemas lineares.

Na seção (\ref{sec:sys_ident_classic_structs}) foi apresentado o conceito de conjunto de modelos para
sistemas lineares. Nesta seção será apresentado de forma análoga o conceito de conjunto de modelos  para
sistemas não lineares. 

Modelos para sistemas podem ser divididos em dois grupos principais, baseados na natureza de suas não
linearidades: não linearidades estáticas, onde a dinâmica do sistema pode ser bem caracterizada por um modelo
linear enquanto que a parte naõ linear está concentrado ou na entrada ou na saída do sistema de forma estática.
Para estes sistemas a forma mais usual de caracterizar é utilizando o método de Wiener para não lineridades
na saída do processo ou o modelo de Hammerstein, quando a não linearidade está na entrada do processo.

Para os demais casos, onde a não linearidade está na dinâmica do processo existem várias familias de modelos
que podem ser utilizados como será visto no decorrer deste capítulo. De forma geral todos estes conjuntos
possuem em comum a idéia da escolha de uma base que seja representativa e que possa reduzir a quantidade de
termos a ser identificado e com isso ter uma boa aproximação do sistema real com a menor quantidade de
parametros possível.

Percebe-se então que um mesmo sistema pode ser representado por diversos destes modelos, mas dependendo das
caracteristicas deste sistema, uma das famílias de modelos será mais adequada, por sua base possuir mais
facilidade em representar certo tipo de não linearidades.

Um dos passos mais desafiadores na construção de modelos não lineares é a escolha da estrutura de
modelo. Quando este modelo é não linear, existe uma grande quantidade de opções e com isso o perigo
de escolher um modelo desnecessariamente complexo é evidente. Isso baseia-se no {\it{principio
da parsemônia}} que basicamente determina que o modelo deve ser o mais simples possível.
\cite{aguirre_maps}

Uma das primeiras justificativas para o desenvolvimento de métodos para a escolha de famílias de modelos é a
grande dificuldade de trabalhar com modelos com muitos parametros, por tornarem-se desta forma complexos e
grandes. Existe o problema destes modelos serem numericamente mal condicionados além da convicção de que estes
modelos (com muitos parâmetros) são redundantes e poderiam ser removidos do modelo. Um modelos com um número
excessivo de parâmetros podem exibir dinâmicas que não são observadas no sistema real, desta forma não existe
apenas o problema numérico para estes sistemas, mas também um problema de dinâmica em utilizar um
modelo sobre-estimado. \cite{aguirre_jacome}

%TODO: achar onde por isso e se nao tem nada melhor no paper para adicionar
%Um problema fundamental referente a modelos parametrizados refere-se ao fato do
%parâmetro poder ou não ser determinado a partir dos valores medidos de entrada e saída. \cite{glad_ljung}

% ===============================================================================
\subsection{Modelos de Wiener e Hammerstein}
\label{sec:nl_models_wiener_hammerstein}
% Aguirre: 334
% ljung 143
%===============================================================================

Modelos de Wiener e Hammerstein são normalmente utilizados em situações onde a dinâmica do sistema pode ser bem
descrita por um sistema linear, mas existem algumas não linearidades estáticas atreladas a entrada
e/ou a saída. Este será o caso de atuadores serem não lineares como por exemplo: devido a saturação,
ou se o sensor tem características não lineares.

Um modelo com não linearidades na entrada é chamado de {\it{modelo de Hammerstein}} e 
para não linearidades na saída chama-se {\it{modelo de Wiener}}. \cite{ljung}

Na Figura (\ref{fig:nl_models_hammerstein_wiener}) observa-se o diagrama de bloco para os modelos
de Hammerstein e Wiener.


\begin{figure}[htbp]
\center
\scalebox{1} % Change this value to rescale the drawing.
{
\begin{pspicture}(0,-1.6)(9.439062,1.6)
\usefont{T1}{ptm}{m}{n}
\rput(0.52453125,1.31){$u(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(3.9557812,1.31){$f(u(t))$}
\usefont{T1}{ptm}{m}{n}
\rput(7.554531,1.35){$y(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(5.8759375,1.15){Modelo}
\usefont{T1}{ptm}{m}{n}
\rput(5.7834377,0.75){Linear}
\usefont{T1}{ptm}{m}{n}
\rput(2.1957812,1.03){$f(\cdot)$}
\psframe[linewidth=0.04,dimen=outer](3.0,1.6)(1.2,0.4)
\psframe[linewidth=0.04,dimen=outer](6.8,1.6)(5.0,0.4)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(3.0,1.0)(5.0,1.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(0.0,1.0)(1.2,1.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(6.8,1.0)(8.0,1.0)
\usefont{T1}{ptm}{m}{n}
\rput(0.52453125,-0.69){$u(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(3.9357812,-0.69){$z(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(2.0759375,-0.85){Modelo}
\usefont{T1}{ptm}{m}{n}
\rput(1.9834375,-1.25){Linear}
\usefont{T1}{ptm}{m}{n}
\rput(5.9957814,-0.99){$f(\cdot)$}
\psframe[linewidth=0.04,dimen=outer](3.0,-0.4)(1.2,-1.6)
\psframe[linewidth=0.04,dimen=outer](6.8,-0.4)(5.0,-1.6)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(3.0,-1.0)(5.0,-1.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(0.0,-1.0)(1.2,-1.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(6.8,-1.0)(8.0,-1.0)
\usefont{T1}{ptm}{m}{n}
\rput(8.204532,-0.65){$y(t)=f(z(t))$}
\end{pspicture} 
}
\caption{Acima: modelo de Hammerstein. Abaixo: Modelo de Wiener.}
\label{fig:nl_models_hammerstein_wiener}
\end{figure}

%===============================================================================
\subsection{Serie de volterra}
\label{sec:nl_models_volterra}
% Aguirre 334
%===============================================================================

Um sistema não linear pode ser descrito pela serie de Volterra \eqref{eq:nl_models_volterra}:

\begin{equation}
y(t)=\sum_{j=1}^{\infty}\int_{-\infty}^{\infty}\cdots \int_{-\infty}^{\infty}
h_j(\tau_1, ... ,\tau_j) \prod_{i=1}^{j}u(t-\tau_i)d\tau_i
\label{eq:nl_models_volterra}
\end{equation}

Onde $h_j$ são generalizações não lineares da resposta ao impulso $h_1(t)$ . Para
um sistema linear com $j=1$ a equação de Volterra se reduz a integral de convolução.
\cite{aguirre}

As expansões funcionais em series de Volterra relacionam os sinais passados da entrada com o valor atual da saída do
sistema e isso inevitavelmente significa que que um conjnto exessivo de parametros é necessário para descrever até mesmo
sismples sistemas não lineares e consequentemente apenas poucas aplicações práticas foram apresentadas.
\cite{chen_billings1989}

%===============================================================================
\subsection{Redes Neurais}
\label{sec:nl_models_neurals}
% TODO: Search for bib
%===============================================================================
As redes neurais artificiais são compostas por camadas de neurônios interconectados. A saída de um
neurônio com $n$ entradas é apresentado na equação \eqref{eq:nl_models_neural}

\begin{equation}
x=\emph{f}\left ( \sum_{j=1}^{n}\omega_j x_j +b \right )
\label{eq:nl_models_neural}
\end{equation}

Sendo que $b$ (bias) e $\omega_j$ são constantes e $\emph{f}$ é chamada de função de ativação. A
função de ativação mais comum é: \cite{aguirre}

\begin{equation}
\emph{f}(z)=\frac{1}{1+e^{-z}}
\nonumber
\end{equation}


%===============================================================================
\subsubsection{Redes Neurais multi-camadas}
\label{sec:nl_models_neurals_multilayer}
%===============================================================================

Uma tipica rede multi-camadas pode ser descrita como na Figura
(\ref{fig:nl_models_neural_multilayer}).  Na pratica redes neurais multi-camadas tem grande apelo no
reconhecimento de padrões. Do ponto de vista teórico os sistemas de redes multi-camadas podem ser
considerados como mapas não lineares onde os elementos das matrizes de peso são os parâmetros.
\cite{narenda_parthasarathy}

\begin{figure}[htbp]
\center
\scalebox{0.85} % Change this value to rescale the drawing.
{
\begin{pspicture}(0,-3.369375)(14.589063,3.329375)
\pscircle[linewidth=0.04,dimen=outer](4.77,2.729375){0.4}
\usefont{T1}{ptm}{m}{n}
\rput(4.804531,2.699375){$\sum$}
\psframe[linewidth=0.04,dimen=outer](7.17,3.329375)(5.97,2.129375)
\usefont{T1}{ptm}{m}{n}
\rput(6.534531,2.759375){$\gamma$}
\pscircle[linewidth=0.04,dimen=outer](4.77,0.529375){0.4}
\usefont{T1}{ptm}{m}{n}
\rput(4.804531,0.499375){$\sum$}
\psframe[linewidth=0.04,dimen=outer](7.17,1.129375)(5.97,-0.070625)
\usefont{T1}{ptm}{m}{n}
\rput(6.534531,0.559375){$\gamma$}
\pscircle[linewidth=0.04,dimen=outer](4.77,-1.870625){0.4}
\usefont{T1}{ptm}{m}{n}
\rput(4.804531,-1.900625){$\sum$}
\psframe[linewidth=0.04,dimen=outer](7.17,-1.270625)(5.97,-2.470625)
\usefont{T1}{ptm}{m}{n}
\rput(6.534531,-1.840625){$\gamma$}
\pscircle[linewidth=0.04,dimen=outer](10.37,2.729375){0.4}
\usefont{T1}{ptm}{m}{n}
\rput(10.384531,2.679375){$\sum$}
\psframe[linewidth=0.04,dimen=outer](12.77,3.329375)(11.57,2.129375)
\usefont{T1}{ptm}{m}{n}
\rput(12.254531,2.739375){$\gamma$}
\pscircle[linewidth=0.04,dimen=outer](10.37,0.529375){0.4}
\usefont{T1}{ptm}{m}{n}
\rput(10.384531,0.479375){$\sum$}
\psframe[linewidth=0.04,dimen=outer](12.77,1.129375)(11.57,-0.070625)
\usefont{T1}{ptm}{m}{n}
\rput(12.254531,0.539375){$\gamma$}
\pscircle[linewidth=0.04,dimen=outer](10.37,-1.870625){0.4}
\usefont{T1}{ptm}{m}{n}
\rput(10.384531,-1.920625){$\sum$}
\psframe[linewidth=0.04,dimen=outer](12.77,-1.270625)(11.57,-2.470625)
\usefont{T1}{ptm}{m}{n}
\rput(12.254531,-1.860625){$\gamma$}
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(5.17,2.729375)(5.97,2.729375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(5.17,0.529375)(5.97,0.529375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(5.37,-1.870625)(5.97,-1.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(10.77,2.729375)(11.57,2.729375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(10.77,0.529375)(11.57,0.529375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(10.77,-1.870625)(11.57,-1.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(12.77,2.729375)(13.97,2.729375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(12.77,0.529375)(13.97,0.529375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(12.77,-1.870625)(13.97,-1.870625)
\usefont{T1}{ptm}{m}{n}
\rput(13.674531,3.039375){$y_1$}
\usefont{T1}{ptm}{m}{n}
\rput(13.674531,0.839375){$y_2$}
\usefont{T1}{ptm}{m}{n}
\rput(13.674531,-1.560625){$y_n$}
\psdots[dotsize=0.12](6.77,-0.470625)
\psdots[dotsize=0.12](6.77,-0.670625)
\psdots[dotsize=0.12](6.77,-0.870625)
\psdots[dotsize=0.12](12.37,-0.470625)
\psdots[dotsize=0.12](12.37,-0.670625)
\psdots[dotsize=0.12](12.37,-0.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,2.729375)(9.97,2.729375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,2.729375)(9.97,0.529375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,2.729375)(9.97,-1.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,0.529375)(9.97,0.529375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,-1.870625)(9.97,-1.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,0.529375)(9.97,2.729375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,0.529375)(9.97,-1.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,-1.870625)(9.97,0.529375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(7.1873198,-1.870625)(9.97,2.729375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7888126,2.7075653)(4.37,2.7075653)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7888126,2.7075653)(4.37,0.51799595)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7888126,2.7075653)(4.37,-1.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7871279,0.529375)(4.37,0.529375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7871279,-1.850625)(4.37,-1.850625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7871279,0.529375)(4.37,2.729375)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7871279,0.529375)(4.37,-1.870625)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7871279,-1.850625)(4.37,0.5389402)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.7871279,-1.850625)(4.37,2.729375)
\usefont{T1}{ptm}{m}{n}
\rput(1.4745313,3.039375){$u_1$}
\usefont{T1}{ptm}{m}{n}
\rput(1.4745313,0.839375){$u_2$}
\usefont{T1}{ptm}{m}{n}
\rput(1.4745313,-1.560625){$u_n$}
\usefont{T1}{ptm}{m}{n}
\rput(1.4845313,-3.160625){$\text{Entrada}$}
\usefont{T1}{ptm}{m}{n}
\rput(6.7345314,-3.160625){$\text{Camada Oculta}$}
\usefont{T1}{ptm}{m}{n}
\rput(12.444531,-3.160625){$\text{Camada Saída}$}
\end{pspicture} 
}

\caption{Rede neural multi-camadas.}
\label{fig:nl_models_neural_multilayer}
\end{figure}

A saída do sistema para uma rede multi-camadas pode ser descrito como em
\eqref{eq:nl_models_neural_multilayer}.

\begin{equation}
y(t)=f_s\left \{ \sum_{i=1}^{m} \omega_i f_i \left ( \sum_{j=1}^{n}\omega_{ij} x_j + b_i \right ) +
b_s \right \}
\label{eq:nl_models_neural_multilayer}
\end{equation}

Sendo que $f_s$ é a função de ativação do neurônio da camada de saída. Esta função não precisa ser
igual a $f_i$, $i=1, \ldots , m$ que por sua vez não precisam ser iguais entre si. $b_s$ é o termo
de polarização do neurônio da camada de saída, $\omega_i$ são os pesos da saída de cada neurônio da
camada oculta e $\omega_{ij}$ são os pesos da entrada $j$, vista pelo $i-$ésimo neurônio da camada
oculta. \cite{aguirre}

%===============================================================================
\subsubsection{Redes Neurais recorrentes}
\label{sec:nl_models_neurals_multilayer}
%===============================================================================

Redes neurais recorrentes, trabalho introduzido por Hopfield em \cite{hopfield} provê uma
alternativa para o reconhecimento de padrões. O método proposto consiste em ter uma rede neural de
apenas uma camada adicionada de uma realimentação com um atraso de tempo como apresentado na Figura
(\ref{fig:nl_models_neural_recurrent}). \cite{narenda_parthasarathy}

\begin{figure}[htbp]
\center
\scalebox{0.85} % Change this value to rescale the drawing.
{
\begin{pspicture}(0,-5.4)(11.04,5.4)
\usefont{T1}{ptm}{m}{n}
\rput(8.015624,4.91){$\gamma$}
\usefont{T1}{ptm}{m}{n}
\rput(8.015624,3.31){$\gamma$}
\usefont{T1}{ptm}{m}{n}
\rput(8.215624,0.71){$\gamma$}
\usefont{T1}{ptm}{m}{n}
\rput(5.073437,-0.89){$z^{-1}$}
\pscircle[linewidth=0.04,dimen=outer](6.42,4.8){0.4}
\pscircle[linewidth=0.04,dimen=outer](6.42,0.6){0.4}
\pscircle[linewidth=0.04,dimen=outer](6.42,3.2){0.4}
\usefont{T1}{ptm}{m}{n}
\rput(6.395625,0.61){$\sum$}
\usefont{T1}{ptm}{m}{n}
\rput(6.395625,3.21){$\sum$}
\usefont{T1}{ptm}{m}{n}
\rput(6.395625,4.81){$\sum$}
\psdots[dotsize=0.12](5.82,4.8)
\psdots[dotsize=0.12](5.82,3.2)
\psdots[dotsize=0.12](5.82,0.6)
\psdots[dotsize=0.12](2.82,4.8)
\psdots[dotsize=0.12](2.82,3.2)
\psdots[dotsize=0.12](2.82,0.6)
\psline[linewidth=0.04cm](2.82,4.8)(5.82,4.8)
\psline[linewidth=0.04cm](2.82,4.8)(5.82,3.1916058)
\psline[linewidth=0.04cm](2.82,4.8)(5.82,0.61817497)
\psline[linewidth=0.04cm](2.82,0.61817497)(5.82,4.8)
\psline[linewidth=0.04cm](2.82,3.1916058)(5.82,4.8)
\psline[linewidth=0.04cm](2.82,3.1916058)(5.82,3.1916058)
\psline[linewidth=0.04cm](2.82,3.1916058)(5.82,0.61817497)
\psline[linewidth=0.04cm](2.82,0.61817497)(5.82,3.1916058)
\psline[linewidth=0.04cm](2.82,0.61817497)(5.82,0.61817497)
\psline[linewidth=0.04cm](8.8,0.6)(9.42,0.6)
\psline[linewidth=0.04cm](9.4,-1.0)(5.8,-1.0)
\psline[linewidth=0.04cm](4.62,-1.0)(1.6,-1.0)
\psline[linewidth=0.04cm](1.62,0.6)(2.82,0.6)
\psline[linewidth=0.04cm](6.82,0.6)(7.62,0.6)
\psline[linewidth=0.04cm](5.82,0.6)(6.0,0.6)
\psline[linewidth=0.04cm](6.82,3.2)(7.62,3.2)
\psline[linewidth=0.04cm](5.82,3.2)(6.02,3.2)
\psline[linewidth=0.04cm](5.82,4.8)(6.02,4.8)
\psline[linewidth=0.04cm](6.82,4.8)(7.62,4.8)
\psline[linewidth=0.04cm](8.8,3.2)(10.22,3.2)
\psline[linewidth=0.04cm](5.8,-2.6)(10.2,-2.6)
\psline[linewidth=0.04cm](8.8,4.8)(11.02,4.8)
\psline[linewidth=0.04cm](11.0,-4.8)(5.8,-4.8)
\psline[linewidth=0.04cm](4.62,-2.6)(0.8,-2.6)
\psline[linewidth=0.04cm](0.8,3.2)(2.82,3.2)
\psline[linewidth=0.04cm](2.82,4.8)(0.0,4.8)
\psline[linewidth=0.04cm](0.0,-4.8)(4.62,-4.8)
\psdots[dotsize=0.12](8.22,2.2)
\psdots[dotsize=0.12](8.22,2.0)
\psdots[dotsize=0.12](8.22,1.8)
\psdots[dotsize=0.12](5.22,-3.4)
\psdots[dotsize=0.12](5.22,-3.6)
\psdots[dotsize=0.12](5.22,-3.8)
\usefont{T1}{ptm}{m}{n}
\rput(9.864062,5.11){$x_1(t+1)$}
\usefont{T1}{ptm}{m}{n}
\rput(9.864062,3.51){$x_2(t+1)$}
\usefont{T1}{ptm}{m}{n}
\rput(9.864062,0.91){$x_n(t+1)$}
\usefont{T1}{ptm}{m}{n}
\rput(2.0040624,5.11){$x_1(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(2.0040624,3.51){$x_2(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(2.0040624,0.91){$x_n(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(4.3840623,5.11){$\omega_i$}
\usefont{T1}{ptm}{m}{n}
\rput(5.073437,-2.49){$z^{-1}$}
\usefont{T1}{ptm}{m}{n}
\rput(5.073437,-4.69){$z^{-1}$}
\psframe[linewidth=0.04,dimen=outer](8.8,5.4)(7.6,4.2)
\psframe[linewidth=0.04,dimen=outer](8.8,3.8)(7.6,2.6)
\psframe[linewidth=0.04,dimen=outer](8.8,1.2)(7.6,0.0)
\psframe[linewidth=0.04,dimen=outer](5.8,-0.4)(4.6,-1.6)
\psframe[linewidth=0.04,dimen=outer](5.8,-2.0)(4.6,-3.2)
\psframe[linewidth=0.04,dimen=outer](5.8,-4.2)(4.6,-5.4)
\psline[linewidth=0.04cm](11.0,4.8)(11.0,-4.8)
\psline[linewidth=0.04cm](10.2,3.2)(10.2,-2.6)
\psline[linewidth=0.04cm](9.4,0.6)(9.4,-1.0)
\psline[linewidth=0.04cm](1.6,0.6)(1.6,-1.0)
\psline[linewidth=0.04cm](0.8,-2.6)(0.8,3.2)
\psline[linewidth=0.04cm](0.0,4.8)(0.0,-4.8)
\end{pspicture} 
}
\caption{Rede neural recorrentes.}
\label{fig:nl_models_neural_recurrent}
\end{figure}

%===============================================================================
\subsection{Funções Radiais de Base}
\label{sec:nl_models_radiais}
% Aguirre 337
%===============================================================================

Funções radiais de base  ({\it{RBF - Radial basis functions}})  são uma tradicional técnica para
interpolação em espaços multidimensional \cite{chen_billings_narmax} e podem ser descritos como
mapeamentos do tipo \eqref{eq:nl_models_rbf}:

\begin{equation}
f(y)-w_0+\sum_{i}w_i \phi (\left \| y-c_i \right \|)
\label{eq:nl_models_rbf}
\end{equation}

Sendo que $y \in \mathbb{R}^{d_e}$ ($d_e$ é conhecido como dimensão de imersão),
$\left \| \cdot \right \|$ é a norma euclidiana, $w_i \in \mathbb{R}$ são pesos, 
$c_i \in \mathbb{R}^{d_e}$ são centros e $\phi(\cdot):\mathbb{R}^+ \to \mathbb{R}$ 
é uma função, normalmente escolhida a priori, como por exemplo: \cite{aguirre}

\begin{equation}
\phi(\left \| y-c_i \right \|)= exp\left ( -\frac{\left \| y-c_i \right \|^2}{\sigma_i^2} \right )
\nonumber
\end{equation}

Outras funções de base usadas são apresentadas na Tabela \ref{table:nl_models_rbf}

\begin{table*}[htbp]
\begin{center}
\caption{Algumas funções Radiais de base comumente utilizadas.}
\label{table:nl_models_rbf}
\begin{tabular}{ll}
\hline
        Nome & Função   \\
\hline
        Multi quadrática inversa  & $\phi(r)=(r^2+\sigma ^2)^{-1/2}$ \\ 
        Linear                    & $\phi(r)=r$                      \\ 
        Cúbica                    & $\phi(r)=r^3$                    \\ 
        Multi-quadrática           & $\phi(r)=\sqrt{r^2+\sigma^2}$    \\ 
        {\it{Thin - plate spline}} & $\phi(r)=r^2\; \text{log}(r)$   \\ 
\hline
\end{tabular}
\end{center}
\end{table*}

Sendo que $r=\left \| y-c_i \right \|$ e $\sigma$ definem a largura do chapéu no caso de
funções gausianas e das multiquadráticas, como pode ser visto na figura (\ref{fig:nl_models_rbf}).

\begin{figure}[htbp]
	\center
	\includegraphics[width=0.8\columnwidth]{figures/nl_models_rbf.eps}
	\caption{Função multiquadráticas inversa para alguns valores de $\sigma$.}
	\label{fig:nl_models_rbf}
\end{figure}

Este tipo de representação tem boas propriedades locais e pode ser interpretada como 
uma técnica de interpolação global. Funções radiais de base são casos particulares
de redes neurais, porem neste caso lineares nos parâmetros $w_i$.\cite{aguirre} 

No contexto de identificação de sistemas é comum adicionar termos auto-regressivos
lineares, bem como termos de entrada à equação \eqref{eq:nl_models_rbf} resultando em:

\begin{equation}
y(k)=w_0 + \sum_{i}w_i \phi(\left \| \mathbf{y}(k-1)-c_i \right \|)+\sum_{i=1}^{n_y}a_i y(k-i)+\sum_{i=1}^{n_u}b_i u(k-i)+e(k)
\nonumber
\end{equation}

Sendo $\mathbf{y}(k-1)=\begin{bmatrix}
y(k-1) & ... & y(k-n_y) & u(k-1) & ... & u(k-n_u)
\end{bmatrix}$.

%===============================================================================
\section{Modelos NARMAX}
\label{sec:nl_models_narmax}
% Aguirre 343
%===============================================================================

Os modelos {\it{NARX}} (do termo ingles {\it{nonlinear autoregressive model with
exogenous variables}}) são modelos discretos no tempo que caracterizam o valor da saída em função
dos valor passados da entrada e saída. Algumas vezes, para evitar a polarização da estimativa dos
parâmetros adiciona-se termos do ruido no modelo. Quando isso é feito o modelo passa a ser chamado
de um modelo {\it{NARMAX}} (do termo inglês {\it{nonlinear autoregressive moving average model with
exogenous variables}}), introduzidos por \cite{leontaritis_billings1985}, que pode ser representado
pela equação \eqref{eq:nl_model_narmax} \cite{aguirre}. Este modelo provê uma representação
unificada para a descrição de sistemas discretos não lineares \cite{chen_billings_narmax}

Leontaritis e Billings em \cite{chen_billings1989} rigorozamente provaram que um sistema não linear
de tempo discreto LTI pode sempre ser representado por um modelo do tipo:

\begin{equation}
y(t)=F(y(t-1), \cdots, y(t-n_y),u(t-1), \cdots, u(t-n_u) )
\label{eq:nlin_models_narmax_generic}
\end{equation}

Em uma região ao redor do ponto de equilibrio sugeito a duas condições:

\begin{enumerate}
\item a resposta da função $F$ do sistema deve ser finitamente realizavel.
\item Um modelo linearizado existe se o sistema é operado próximo ao ponto de equilibrio escolhido.
\end{enumerate}

Observa-se que a condição (1) apenas exclui sistemas de parametros distribuidos e a condição (2) implica que se o
sistema for perturbado com uma amplitude pequena, em volta da região do ponto de quilibrio, um modelo linearizado do
sistema existe. \cite{chen_billings1989}

O modelo {\it{NARMAX}} surgiu, ou foi motivado, pelo exessivo esforço para a estimativa dos
parametros e pela dificuldade em interpretar os resultados obtidos com modelos baseados em series
(Wienner, Hammerstein e Volterra). A necessidade do uso de entradas espaciais são também uma
desvantagem detes modelos. \cite{leontaritis_billings1985}

\begin{eqnarray}\nonumber
y(t)&=&F [ y(t-1), ..., y(t-n_y), u(t-1), ... , u(t-n_u),\\
&&  e(t),e(t-1), ... , e(t-n_e) ]
\label{eq:nl_model_narmax}
\end{eqnarray}

Onde $e(t)$ é o ruido e $n_e$ é o maior atraso no modelo do ruido. O modelo apresentado
em \eqref{eq:nl_model_narmax} é bastante genérico, caracterizando uma dificuldade 
para sua utilização. A caracterização da equação $F$ geralmente é feita pelas 
representações polinomial e racional. Um modelo polinomial {\it{NARMAX}} sem atraso
puro de tempo tem a forma apresentada em \eqref{eq:nl_model_narmax_pol}.

\begin{equation}
y(t)=\sum_{i}c_i \prod_{j=1}^{n_y}y(t-j) \prod_{r=1}^{n_u}u(t-r) \prod_{q=0}^{n_e}e(t-q)
\label{eq:nl_model_narmax_pol}
\end{equation}

Os modelos polinomiais {\it{bilineares}} são casos particulares do modelo polinomial 
\eqref{eq:nl_model_narmax_pol} quando todos os termos não lineares são do tipo 
$y(t-i)u(t-j), \; \forall i,j$. \cite{aguirre}

Modelos racionais são formados pela razão entre dois polinômios \eqref{eq:nl_model_narmax_rat}.

\begin{equation}
y(t)=\frac{\sum_{i}c_i \prod_{j=1}^{n_y}y(t-j) \prod_{r=1}^{n_u}u(t-r) \prod_{q=0}^{n_e}e(t-q)}
{\sum_{i}d_i \prod_{j=1}^{d_y}y(t-j) \prod_{r=1}^{d_u}u(t-r) \prod_{q=0}^{d_e}e(t-q)} + e(t)
\label{eq:nl_model_narmax_rat}
\end{equation}

Em função de terem uma estrutura mais flexível, os modelos racionais podem vir a ser
mais eficientes na modelagem de certos sistemas quando comparados com modelos polinomiais.
Entretanto, os modelos racionais são mais sensíveis ao ruido. \cite{aguirre}

%===============================================================================
\subsection{Modelo polinomial}
\label{sec:nl_models_narmax_pol}
% Aguirre 343
%===============================================================================
Com relação ao modelo genérico polinomial {\it{NARMAX}} apresentado em \eqref{eq:nl_model_narmax_pol}
duas considerações serão levadas em conta:

\begin{enumerate}
\item O sistema tem um atraso puro de tempo $\tau _d$.
\item Nenhum termo cujo parâmetro tenha que ser estimado pode depender de $e(t)$.
\end{enumerate}

A segunda consideração implica em tornar $F$ independente de $e(t)$. O que equivale a dizer
que $q=1$ em \eqref{eq:nl_model_narmax_pol} resultando em  \eqref{eq:nl_model_narmax_pol_espec}.

\begin{eqnarray}\nonumber
y(t) &=& F[ y(t-1), ..., y(t-n_y), u(t-\tau_d), ..., u(t-\tau_d-n_u+1),\\
&& e(t-1), ..., e(t-n_e)] +e(t)
\label{eq:nl_model_narmax_pol_espec}
\end{eqnarray}

$e(t)$ indica que todos os efeitos não podem ser bem representados. $F^l\left [ \cdot  \right ]$ é
uma função polinomial de $y(t)$, $u(t)$ e $e(t)$ com grau de não linearidade $l\in \mathbb{N}$. 
Portanto a parte não determinística de \eqref{eq:nl_model_narmax_pol_espec} pode ser expandida como
um somatório de termos com grau de não linearidade variando de $1 \le m \le l$. 
Assim sendo, cada termo de grau $m$ poderá conter um valor de grau $p$ do tipo $y(t-i)$
e um fator de grau $(m-p)$ do tipo $u(t-i)$ sendo multiplicado por um parâmetro representado 
por $c_{p,m-p}(n_1, ..., n_m)$. Resultando em: \cite{aguirre}

\begin{equation}
y(t)=\sum_{m=0}^{l}\sum_{p=0}^{m}\sum_{n1, n_m}^{n_y, n_u}c_{p,m-p}(n_1,...,n_m)\prod_{i=1}^{p}y(t-n_i)\prod_{i=p+1}^{m}u(t-n_i)
\nonumber
\end{equation}


%===============================================================================
\subsection{Modelo Racional}
\label{sec:nl_models_narmax_rat}
% Aguirre 345
%===============================================================================

Um modelo racional {\it{NARMAX}} tem a seguinte forma geral apresentada em 
\eqref{eq:nl_model_narmax_rat} e de forma simplificada pode ser apresentado como em
\eqref{eq:nl_model_narmax_rat_simp}.

\begin{equation}
y(k)=\frac{a(\Upsilon)}{b(\Upsilon)}+e(t)
\label{eq:nl_model_narmax_rat_simp}
\end{equation}

Onde:

\begin{equation}
\Upsilon=\left \{ y(t-1), ..., y(t-n_y), u(t-1), ..., u(t-n_u), e(t-1), ..., e(t-n_e)\right \}
\nonumber
\end{equation}

No modelo apresentado em \eqref{eq:nl_model_narmax_rat_simp}, as funções $a(\Upsilon)$ e $b(\Upsilon)$
são polinômios, mas poderiam ser quaisquer funções. Assumindo que o modelo é formado pela razão de
dois polinômios, é conveniente definir o numerador e denominador de \eqref{eq:nl_model_narmax_rat_simp}
como em:

\begin{equation}
a(t-1)=\sum_{j=1}^{N_n}p_{nj}\theta_{nj}=\psi _n^T(k-1)\theta_n
\label{eq:nl_model_narmax_rat_num}
\end{equation}


\begin{equation}
b(t-1)=\sum_{j=1}^{N_d}p_{dj}\theta_{dj}=\psi _d^T(k-1)\theta_d
\label{eq:nl_model_narmax_rat_den}
\end{equation}

Sendo que $\theta_{nj}$ e $\theta_{dj}$ são os parâmetros dos regressores, possuindo informações até
o instante $t-1$. Desta forma o valor de parâmetros a ser estimados é $N_n + N_d$

A equação \eqref{eq:nl_model_narmax_rat_simp} possui não linearidade nos parâmetros, tornando a
identificação mais complexa por não ser possível utilizar o método dos mínimos quadrados para a
estimativa dos parâmetros. Uma alternativa para este problema é multiplicar a equação
\eqref{eq:nl_model_narmax_rat_simp} pela equação \eqref{eq:nl_model_narmax_rat_den} em ambos os seus
lados. \cite{billings_zhu91}

\begin{equation}
Y(t)=a(t)-y(t)\sum_{j=2}^{den}p_{dj}(t)\theta_{dj}+b(t)e(t)
\nonumber
\end{equation}


\begin{equation}
Y(t)=\sum_{j=1}^{num}p_{nj}(t)\theta_{nj}-\sum_{j=2}^{den}y(t)p_{dj}(t)\theta_{dj}+\xi (t)
\label{eq:nl_model_narmax_rat_linear_param}
\end{equation}

Onde:

\begin{equation}
Y(t)=y(t)p_{d1}\mid_{\theta_{d1}=1} =p_{d1}(t)\frac{a(t)}{b(t)}+p_{d1}(t)e(t)
\nonumber
\end{equation}

E

\begin{equation}
\xi(t)=b(t)e(t)=\left ( \sum_{j=1}^{den}p_{dj}(t)\theta_{dj} \right )e(t)
\nonumber
\end{equation}

Pelo fato de $e(t)$ ser independente de $b(t)$ e ter média nula, tem-se:

\begin{equation}
E\left [ \xi(t) \right ]=E\left [ b(t) \right ]E\left [ e(t) \right ]=0
\label{eq:nl_model_narmax_rat_noise_var}
\end{equation}

A equação \eqref{eq:nl_model_narmax_rat_noise_var} mostra que todos os termos $y(t)p_{dj}(t)$
incluem o termo de ruido $e(t)$ através de $y(t)$ que este por sua vez é altamente relacionado com
$\xi(t)$, o que resultará em polarização dos parâmetros, mesmo que $e(t)$ seja um ruido branco com
média zero. Este é de certa forma o preço que se paga ao linearizar os parâmetros para que seja
possível utilizar o método dos mínimos quadrados. \cite{aguirre}

Uma das maiores desvantagens da modelo racional quando comparado com o modelo polinomial é que o modelo polinomial é
linear nos parametros. Muitos resultados para identificação de sistemas lineares podem ser extendidos para modelos
polinomiais não lineares e várias rotinas de determinação de estrutura foram desenvolvidas. \cite{chen_billings1989}
