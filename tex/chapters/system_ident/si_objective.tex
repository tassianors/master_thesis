%===============================================================================
\section{Objetivo}
\label{sec:sys_ident_objective}
%===============================================================================



Pode-se considerar $y(t)$ como a saída do modelo matemático quando submetido a uma entrada $u(t)$ e
$\hat{y}(t)$ a saída real do sistema quando excitado pelo sinal de entrada $u(t)$. Os sinais $u(t)$
e $\hat{y}(t)$ são medidos pelo usuário.

Considerando o erro entre o sinal real $\hat{y}(t)$  e o sinal do modelo matemático $y(t)$ como:

\begin{equation}
\varepsilon (t)=y(t)-\hat{y}(t)
\nonumber
\end{equation}

A regressão linear é o tipo mais simples de modelo paramétrico. A estrutura do modelo
pode ser descrita como abaixo. \cite{system_identification}

\begin{equation}
\hat{y}(t)=\varphi ^T(t)\theta
\label{eq:si_obj_single_var}
\end{equation}

Onde $y(t)$ é chamada de {\it{variável regredida}} e é medida do processo.
$\varphi (t)$ é comumente chamado de {\it{variável de regressão}} e $\theta$ é o vetor de
parâmetros a ser identificado.

Assim, o erro pode ser reescrito como:

\begin{equation}
\varepsilon (t)=\hat{y}(t)-\varphi ^T(t)\theta
\nonumber
\end{equation} 

O objetivo da identificação de sistema, pode ser então expresso como a escolha de um vetor $\hat{\theta}$ que
minimize a função custo:

\begin{equation}
V(\theta)=\frac{1}{2}\sum_{t=1}^{N}\varepsilon ^2(t)=\frac{1}{2}\varepsilon^T\varepsilon=\frac{1}{2}\left \| \varepsilon \right \|
\label{eq:si_obj_etim_lsm_v}
\end{equation}

Com a minimização do erro $\varepsilon (t)$ encontra-se um conjunto de parametros $\theta$ que melhor
consegue representar o relacionamento entre os sinais de entrada $u(t)$ e de saída $\hat{y}(t)$. 

