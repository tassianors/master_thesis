%===============================================================================
\section{Métodos de identificação}
\label{sec:sys_ident_methods}
%===============================================================================
% mains idea of this section:
% MQ
% VI
% Modelagem do ruído

Identificação de sistemas é formada por três premissas básicas: o sistema real $\mathcal{S}$, a classe de modelos
escolhida $\mathcal{M}$ e o critério que determina qual é o melhor modelo dentro da classe $\mathcal{M}$ para
representar o sistema real $\mathcal{S}$.

Métodos de identificação de sistemas envolvem procedimentos, ou algoritmos, para encontrar o mínimo de uma função
custo, conhecida também como critério. Na Seção \ref{sec:sys_ident_intro} foi apresentado o critério de minimização
mais utilizado para a identificação:

\begin{equation}
V(\theta)=\frac{1}{N}\sum_{t=1}^{N}\frac{1}{2} \varepsilon ^2(t, \theta)
\label{eq:si_method_criteria}
\end{equation}

Nesta Seção serão apresentados métodos que minimizam esta função custo, suas propriedades e principais características. 

%===============================================================================
\subsection{Método dos mínimos quadrados}
\label{sec:si_par_estim_lsm}
%===============================================================================

Existem diversos métodos para a estimativa de parâmetros. O mais conhecido remete ao ano de 1809 utilizado por Gauss
para determinação da órbita dos planetas \cite{system_identification}, método este que veio a ser conhecido pelo nome
de método dos mínimos quadrados (MMQ).

Define-se um preditor como em:

\begin{equation}
\hat{y}(t, \theta)=\varphi ^T(t)\theta
\label{eq:si_obj_single_var}
\end{equation}
onde $\hat{y}(t)$ é a predição, $\varphi (t)$ é comumente chamado de {\it{variável de regressão}} e $\theta$ é o vetor
de parâmetros a ser identificado.

A partir do erro de predição apresentado em \eqref{eq:si_estim_prediction_error} e a equação 
\eqref{eq:si_obj_single_var} podemos redefinir o erro de predição como:

\begin{equation}
\varepsilon (t, \theta)=y(t)-\varphi ^T(t)\theta
\nonumber
\end{equation}

A estimativa dos mínimos quadrados é definido como o vetor $\hat{\theta}$ que minimiza a função custo
\eqref{eq:si_method_criteria}. O valor de $\hat{\theta}$ que minimiza esta função custo é dado por:
\cite{system_identification}

\begin{equation}
\hat{\theta}=(\varphi ^T(t) \varphi(t) )^{-1}\varphi  ^T(t) y(t)
\label{eq:si_par_etim_lsm_theta}
\end{equation}

Desta forma o mínimo da função custo fica como em:

\begin{equation}
\underset{\theta}{min}\;V(\theta)=V(\hat{\theta})=\frac{1}{N}\left [ y^Ty-y^T\varphi (\varphi ^T \varphi )^{-1}\varphi
^T y \right ]
\end{equation}

O método dos mínimos quadrados é simples de ser aplicado, mas tem o inconveniente de que para que não existam
erros de polarização na estimativa, a variável de regressão $\varphi(t)$ não pode estar correlacionada com o
distúrbio estocástico $\nu(t)$, ou seja:

\begin{equation}
E \left [  \varphi(t) \nu(t) \right ] = 0
\end{equation}

Assume-se que o sistema real é dado por:

\begin{equation}
y(t)=\varphi^T(t)\theta_0+\nu(t)
\label{eq:si_par_etim_lsm_true_sys}
\end{equation}

Para que as estimativas de $\theta$ tendam a $\theta_0$ quando o número de amostras tende a infinito é necessário que:

\begin{enumerate}
  \item $E \varphi(t)\varphi^T(t)$ seja não singular.
  \item $E \varphi(t)\nu(t) = 0$
\end{enumerate} 

Para a primeira condição algumas exceções são apresentadas: \cite{system_identification}

\begin{itemize}
  \item Se a entrada não for persistentemente excitante.
  \item Os dados não são afetados por ruído ($\nu(t) \equiv 0$) e a ordem da classe de modelos é escolhida com um valor
  muito alto, com relação a ordem do sistema o que implica que $A(q)$ e $B(q)$ possuem fatores comuns. 
  \item A entrada $u(t)$ é gerada por uma realimentação de saída fazendo com que os regressores sejam diretamente
  relacionados com o ruído por meio do sinal $y(t)$.
\end{itemize}

Quando o número de amostras tende ao infinito e a estimativa tende para um valor diferente de $\theta_0$, este erro é
chamado de {\it{bias}} ou erro de polarização da estimativa. Isso ocorrerá quando $\nu(t)$ não for ruído branco. Para
contornar este erro existem duas opções que serão abordadas em seguida: utilização de variáveis instrumentais e 
inclusão da modelagem do ruído na classe de modelos do sistema.

%===============================================================================
\subsection{Método das variáveis instrumentais}
\label{sec:si_par_estim_iv}
%===============================================================================
% bibliografia principal: aguirre e ljung

Como foi apresentado anteriormente, o método dos mínimos quadrados é simples de ser aplicado mas carece de exatidão
quando existe correlação entre a variável de regressão $\varphi(t)$ e o ruído estocástico $\nu(t)$, causando {\it{bias}}
(erro de polarização). Nesta seção será apresentada uma breve discussão sobre um dos métodos que se propõe a sanar este
inconveniente: método das variáveis instrumentais.

Seja $Z(t)$ uma matriz $n\times n$ que possui sinais não correlacionados com o distúrbio $\nu(t)$. O parâmetro $\theta$
deve obedecer a restrição da equação:

\begin{equation}
\frac{1}{N}\sum_{t=1}^{N}Z(t)\varepsilon (t)=\frac{1}{N}\sum_{t=1}^{N}Z(t)\left [ y(t)-\varphi^T(t)\theta \right ]= 0
\label{eq:si_par_estim_iv_theta}
\end{equation}

Se a dimensão da matriz $Z(t)$ for a mesma dimensão do vetor $\theta$ temos o estimador do método das 
variáveis instrumentais:

\begin{equation}
\hat{\theta}=\left [ \sum_{t=1}^{N}Z(t)\varphi^T(t) \right ]^{-1}\left [  \sum_{t=1}^{N}Z(t)y(t) \right ]
\label{eq:si_par_estim_iv}
\end{equation}

Os elementos da matriz $Z(t)$ são normalmente chamados de instrumentos. O estimador das variáveis instrumentais 
é uma generalização do estimador dos mínimos quadrados, quando $Z(t)=\varphi(t)$. \cite{system_identification}

O estimador de variáveis instrumentais evita a polarização desde que o vetor de erro seja não correlacionado
com as variáveis instrumentais. Esta condição é menos restritiva que a condição dos mínimos quadrados para que
não haja erro de polarização. O custo a ser pago por isso envolve: \cite{aguirre}

\begin{enumerate}
\item Escolha das variáveis instrumentais.
\item O estimador resultante é assintoticamente não polarizado, ao invés de ser apenas não polarizado. Ou seja, envolve
a necessidade de um conjunto maior de dados para que a estimativa convirja para o valor final de $\theta$.
\end{enumerate}

Ao escolher as variáveis instrumentais é importante notar que a escolha não deve ser apenas para evitar 
a correlação entre o vetor de erro e os instrumentos. A razão para isso é que os instrumentos 
devem ser tão correlacionadas quanto possível com os regressores do modelo, caso contrário $Z(t)\varphi(t)^T$ 
seria próxima a singular e sua inversa muito mal condicionada. Portanto os instrumentos devem ser, idealmente, 
pouco correlacionados com o erro e muito correlacionados com os regressores do modelo. \cite{aguirre}

A correlação dos instrumentos com os regressores ($E\;Z(t)\varphi(t)^T$) sempre será inferior à correlação dos mínimos
quadrados ($E\;\varphi(t)\varphi(t)^T$) onde temos o regressor correlacionado consigo mesmo . Isso propicia que o uso de
variáveis instrumentais trará uma estimativa com uma variância maior que o método dos mínimos quadrados, pois a
variância da estimativa está relacionada com o inverso de $E\;Z(t)\varphi(t)^T$.

%===============================================================================
\subsection{Modelagem do ruído}
\label{sec:si_par_estim_noise_modeling}
%===============================================================================

O método dos mínimos quadrados possui erro de polarização quando existe correlação entre o regressor $\varphi(t)$ e
$\nu(t)$. Apresentou-se em seguida uma alternativa ao método dos mínimos quadrados que resolve este inconveniente ao
custo da escolha de uma instrumento que não seja correlacionado com o ruído: método das variáveis
instrumentais (do inglês {\it{intrumental variables - IV}}).

Deve-se entretanto salientar que a escolha do instrumento não é o único inconveniente do método variáveis instrumentais.
O aumento do erro de variância, como foi apresentado anteriormente, justifica a busca por outras alternativas para a
estimativa dos parâmetros, almejando um erro de polarização nulo e com o menor erro de variância possível.

Desta forma, tem-se a possibilidade de incluir o modelo do ruído ao processo de identificação. A adição
de $H(q,\theta)$ à identificação traz a vantagem de que quando a classe de modelos $\mathcal{M}$ consegue representar a
totalidade das dinâmicas contidas no sistema real $\mathcal{S}$ então o erro de polarização é zerado. Por questões de
simplicidade de implementação e utilização,  deseja-se que seja possível a utilização do método dos mínimos quadrados
para a realização da estimativa, o que só é possível quando o denominador de $G(q,\theta)$ e $H(q,\theta)$ são iguais.
No caso da estrutura de modelos completa apresentada em \eqref{eq:si_modeling_lti_det_global} e replicado aqui:

\begin{equation}
A(q)y(t)=\frac{B(q)}{F(q)}u(t)+\frac{C(q)}{D(q)}e(t)
\nonumber
\end{equation}
o sistema não é linearmente parametrizável quando todos os polinômios são diferentes do caso unitário ($A(q),\ldots,
F(q) \ne 1$) e com isso a função custo não é convexa, adicionando um grau considerável de complexidade aos algoritmos
para encontrar o mínimo global da equação. \cite{system_identification}