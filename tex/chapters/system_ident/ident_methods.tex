%===============================================================================
\section{Métodos de identificação}
\label{sec:sys_ident_methods}
%===============================================================================
% mains idea of this section:
% MQ
% VI
% Modelagem do ruído

Identificação de sistemas é formado por três premissas básicas: o sistema real $\mathcal{S}$ a classe de modelos
escolhida $\mathcal{M}$ e o critério que determina qual é o melhor modelo dentro da classe.

Métodos de identificação de sistemas envolvem procedimentos, ou algoritmos, para
encontrar o mínimo de uma função custo, chamada critério. Na seção \ref{sec:sys_ident_intro} foi apresentado o critério
de minimização mais utilizado para a identificação:

\begin{equation}
V(\theta)=\frac{1}{N}\sum_{t=1}^{N}\frac{1}{2} \varepsilon ^2(t, \theta)
\label{eq:si_method_criteria}
\end{equation}

Nesta seção serão apresentados métodos que minimizam esta função custo, suas propriedades e características. 

%===============================================================================
\subsection{Método dos mínimos quadrados}
\label{sec:si_par_estim_lsm}
%===============================================================================

Existem diversos métodos para a estimativa de parâmetros. O mais conhecido, remete
ao ano de 1809 utilizado por Gauss para determinação da órbita dos planetas. 
\cite{system_identification}, método este chamado de mínimos quadrados (MMQ).

Um preditor pode ser definido como:

\begin{equation}
\hat{y}(t, \theta)=\varphi ^T(t)\theta
\label{eq:si_obj_single_var}
\end{equation}
onde $\hat{y}(t)$ é a predição, $\varphi (t)$ é comumente chamado de {\it{variável de regressão}} e $\theta$ é o vetor
de parâmetros a ser identificado.

A partir do erro de predição (\ref{eq:si_estim_prediction_error}) e (\ref{eq:si_obj_single_var}) podemos
redefinir o erro de predição como:

\begin{equation}
\varepsilon (t, \theta)=y(t)-\varphi ^T(t)\theta
\nonumber
\end{equation}

A {\it{estimativa dos mínimos quadrados}} é definido como o vetor $\hat{\theta}$ 
que minimiza a função custo (\ref{eq:si_method_criteria}). O valor de $\hat{\theta}$ que minimiza
esta função custo é dada por: \cite{system_identification}

\begin{equation}
\hat{\theta}=(\varphi ^T(t) \varphi(t) )^{-1}\varphi  ^T(t) y(t)
\label{eq:si_par_etim_lsm_theta}
\end{equation}

Desta forma o mínimo da função custo fica como em:

\begin{equation}
\underset{\theta}{min}\;V(\theta)=V(\hat{\theta})=\frac{1}{N}\left [ y^Ty-y^T\varphi (\varphi ^T \varphi )^{-1}\varphi
^T y \right ]
\end{equation}

O método dos mínimos quadrados é simples de ser aplicado, mas tem o inconveniente de que para que não existam
erros de polarização na estimativa, a variável de regressão $\varphi(t)$ não pode estar correlacionada com o
distúrbio estocástico $\nu(t)$, como em:

\begin{equation}
E \left [  \varphi(t) \nu(t) \right ] = 0
\end{equation}

Assume-se que o sistema real é dado por:

\begin{equation}
y(t)=\varphi^T(t)\theta_0+\nu(t)
\label{eq:si_par_etim_lsm_true_sys}
\end{equation}

Para que as estimativas de $\theta$ tendam a $\theta*$ quando o número de amostras tende a infinito é necessário que:

\begin{enumerate}
  \item $E \varphi(t)\varphi^T(t)$ seja não singular.
  \item $E \varphi(t)\nu(t) = 0$
\end{enumerate} 

Para a primeira condição algumas exceções são apresentadas: \cite{system_identification}

\begin{itemize}
  \item Se a entrada não for persistentemente excitante.
  \item Os dados não são afetados por ruído ($\nu(t) \equiv 0$) e a ordem da classe de modelos é escolhida com um valor
  muito alto. O que implica que $A_0(q)$ e $B_0(q)$ possuem fatores comuns. Podendo ocasionar dinâmicas no modelo que
  não existem no sistema real.
  \item A entrada $u(t)$ é gerada por uma realimentação de saída fazendo com que os regressores sejam diretamente
  relacionado com o ruído por meio do sinal $y(t)$.
\end{itemize}

Ao contrário da condição (1), a condição (2) normalmente não é verdadeira. Uma importante exceção é quando $\nu(t)$ é
ruído branco. Para este caso $\nu(t)$ será descorrelacionado com todos os dados passados e em especial com
$\varphi(t)$.\cite{system_identification}

Quando o número de amostras tende ao infinito e a estimativa tende para um valor diferente de $\theta_0$, este erro é
chamado de {\it{bias}} ou erro de polarização da estimativa. Para contornar este erro de {\it{bias}} existem duas opções
que serão abordadas em seguida: Utilização de variáveis instrumentais e modelagem do ruído.

%===============================================================================
\subsection{Método das variáveis instrumentais}
\label{sec:si_par_estim_iv}
%===============================================================================
% bibliografia principal: aguirre e ljung

Como foi visto anteriormente, o método dos mínimos quadrados é simples de ser aplicado mas carece de exatidão
quando existe correlação entre o regressor $\varphi(t)$ e o ruído estocástico $\nu(t)$ causando {\it{bias}} ou erro de
polarização. Nesta seção será apresentado uma breve discussão sobre um dos métodos que se propõe a sanar este
inconveniente do método dos mínimos quadrados: método das variáveis instrumentais.

Seja $Z(t)$ uma matriz $n\times n$ que possui sinais não correlacionados com o 
distúrbio $\nu(t)$. O parâmetro $\theta$ deve obedecer a restrição da equação \eqref{eq:si_par_estim_iv_theta}:

\begin{equation}
\frac{1}{N}\sum_{t=1}^{N}Z(t)\varepsilon (t)=\frac{1}{N}\sum_{t=1}^{N}Z(t)\left [ y(t)-\varphi^T(t)\theta \right ]= 0
\label{eq:si_par_estim_iv_theta}
\end{equation}

Se a dimensão da matriz $Z(t)$ for a mesma dimensão do vetor $\theta$ temos o estimador do método das 
variáveis instrumentais \eqref{eq:si_par_estim_iv}:

\begin{equation}
\hat{\theta}=\left [ \sum_{t=1}^{N}Z(t)\varphi^T(t) \right ]^{-1}\left [  \sum_{t=1}^{N}Z(t)y(t) \right ]
\label{eq:si_par_estim_iv}
\end{equation}

Os elementos da matriz $Z(t)$ são normalmente chamados de instrumentos. O estimador das variáveis instrumentais 
é uma generalização do estimador dos mínimos quadrados, quando $Z(t)=\varphi(t)$. \cite{system_identification}

O estimador de variáveis instrumentais evita a polarização desde que o vetor de erro seja não correlacionado
com as variáveis instrumentais. Esta condição e menos restritiva que a condição dos mínimos quadrados para que
não haja erro de polarização. O valor a ser pago por isso envolve: \cite{aguirre}

\begin{enumerate}[(I)]
\item Escolha das variáveis instrumentais.
\item O estimador resultante é assintoticamente não polarizado, ao invés de ser apenas não polarizado. 
\end{enumerate}

Ao escolher as variáveis instrumentais é importante notar que a escolha não deve ser apenas para evitar 
a correlação entre o vetor de erro e os instrumentos. A razão para isso é que as variáveis instrumentais 
devem ser tão correlacionadas quanto possível com os regressores do modelo, caso contrário $Z(t)\varphi(t)^T$ 
seria próxima a singular e sua inversa muito mal condicionada. Portanto os instrumentos devem ser, idealmente, 
pouco correlacionados com o erro e muito correlacionados com os regressores do modelo. \cite{aguirre}

A correção dos instrumentos com os regressores ($E\;Z(t)\varphi(t)^T$) sempre será inferior à correlação dos mínimos
quadrados ($E\;\varphi(t)\varphi(t)^T$) onde temos o regressor correlacionado consigo mesmo . Isso propicia que o uso de
variáveis instrumentais trará uma estimativa com uma variância maior que o método dos mínimos quadrados, pois a
variância da estimativa está relacionada com o inverso de $E\;Z(t)\varphi(t)^T$.

%===============================================================================
\subsection{Modelagem do ruído}
\label{sec:si_par_estim_noise_modeling}
%===============================================================================

O método dos mínimos quadrados possui erro de polarização quando existe correlação entre o regressor $\varphi(t)$ e
$\nu(t)$. Apresentou-se em seguida uma alternativa ao método dos mínimos quadrados que resolve este inconveniente ao
custo da escolha de uma variável instrumental que não seja correlacionada com o ruído: método das variáveis
instrumentais (do inglês {\it{intrumental variables - IV}}).

Deve-se entretanto salientar que a escolha do instrumento não é o único inconveniente do método variáveis instrumentais.
O aumento do erro de variância, como foi apresentado anteriormente, faz com que se busquem outras alternativas para a
estimativa dos parâmetros, com um erro de polarização nulo, e com o menor erro de variância possível.

Desta forma, tem-se a possibilidade de incluir o modelo do ruído ao processo de identificação. A adição
de $H(z,\theta)$ à identificação traz a vantagem de que quando a classe de modelos $\mathcal{M}$ consegue representar a
totalidade das dinâmicas contidas no sistema real $\mathcal{S}$ então o erro de polarização é zerado. Deseja-se
entretanto que seja possível a utilização do método dos mínimos quadrados, o que é possível quando o denominador de
$G(z,\theta)$ e $H(z,\theta)$ são iguais. No caso da estrutura de modelos completa apresentada em
\eqref{eq:si_modeling_lti_det_global} e replicado aqui

\begin{equation}
A(q)y(t)=\frac{B(q)}{F(q)}u(t)+\frac{C(q)}{D(q)}e(t)
\nonumber
\end{equation}
o sistema não é canonicamente parametrizável quando todos os polinômios são diferentes do caso unitário ($A(q),\ldots,
F(q) \ne 1$) e com isso a função custo não é convexa, adicionando um grau considerável aos algoritmos para encontrar
o mínimo global da equação. \cite{system_identification}

Para estes casos gerais de estruturas de modelos, usa-se o que é chamado de {\it{prediction error method}} (PEM) ou
método do erro de predição. O preditor foi apresentado em \eqref{eq:si_par_estim_predictor} e pode ser reescrito como:

\begin{equation}
\hat{y}(t|t-1, \theta)= L_1(z,\theta)y(t)+ L_2(z,\theta)u(t)
\label{eq:si_par_estim_pem}
\end{equation}
que é uma função de dados passados apenas se os filtros $L_1(z,\theta)$ e $L_2(z,\theta)$ forem construídos obedecendo
a: \cite{system_identification}

\begin{equation}
L_1(0,\theta)=0, \;\;\; L_2(0,\theta)=0
\label{eq:si_par_estim_pem_l_const}
\end{equation}
da onde então pode ser calculado o erro de predição como em: 

\begin{equation}
\varepsilon(t,\theta)=y(t)-\hat{y}(t\mid t-1, \theta)
\label{eq:si_par_estim_pem_l_const}
\end{equation}

Percebe-se que o MMQ é um caso particular do PEM, existem também outros métodos que são casos particulares desta
abordagem, mas nem todos possuem uma função custo quadrática para minimizar, fazendo com que o custo para encontrar este
ponto de mínimo para a função custo seja proporcional a complexidade da curvatura da função custo.




