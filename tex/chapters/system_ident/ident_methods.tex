%===============================================================================
\section{Métodos de identificação}
\label{sec:sys_ident_methods}
%===============================================================================
% mains idea of this section:
% MQ
% VI
% Modelagem do ruído

Identificação de sistemas é formado por três premissas básicas: o sistema real $\mathcal{S}$ a classe de modelos
escolhida $\mathcal{M}$ e o critério que elenca qual é o melhor modelo dentro da classe baseado em algum critério.

Métodos de identificação de sistemas nada mais são do que procedimentos ou algoritmos para encontrar o mínimo de uma
função custo, chamada de critério. Na seção \ref{sec:sys_ident_intro} foi apresentado o critério de minimização mais
utilizado para a identificação:

\begin{equation}
V(\theta)=\frac{1}{2}\sum_{t=1}^{N}\varepsilon ^2(t)=\frac{1}{2}\varepsilon^T\varepsilon=\frac{1}{2}\left \| \varepsilon \right \|
\label{eq:si_method_criteria}
\end{equation}

Nesta seção serão apresentados dois métodos que minimizam a função custo \eqref{eq:si_method_criteria}: Método dos
mínimos quadrados e o método das variáveis instrumentais.

%===============================================================================
\subsection{Método dos mínimos quadrados}
\label{sec:si_par_estim_lsm}
%===============================================================================

Existem diversos métodos para a estimativa de parâmetros. O mais conhecido, remete
ao ano de 1809 utilizado por Gauss para determinação da órbita dos planetas. 
\cite{system_identification}. Método este chamado de mínimos quadrados (MMQ).

A regressão linear é tavez o tipo mais simples de modelo paramétrico. A estrutura do modelo
pode ser descrita como abaixo. \cite{system_identification}

\begin{equation}
\hat{y}(t)=\varphi ^T(t)\theta
\label{eq:si_obj_single_var}
\end{equation}

Onde $y(t)$ é chamada de {\it{variável regredida}} e é medida do processo.
$\varphi (t)$ é comumente chamado de {\it{variável de regressão}} e $\theta$ é o vetor de
parâmetros a ser identificado.

A partir d erro de predição (\ref{eq:si_estim_prediction_error}) e (\ref{eq:si_obj_single_var}) podemos
redefinir o erro de predição como:

\begin{equation}
\varepsilon (t)=y(t)-\varphi ^T(t)\theta
\nonumber
\end{equation}

A {\it{estimativa dos mínimos quadrados}} é definido como o vetor $\hat{\theta}$ 
que minimiza a função custo (\ref{eq:si_obj_etim_lsm_v}). O valor de $\hat{\theta}$ que minimiza
esta função custo é dada por: \cite{system_identification}

\begin{equation}
\hat{\theta}=(\varphi ^T \varphi )^{-1}\varphi  ^T y
\label{eq:si_par_etim_lsm_theta}
\end{equation}

Desta forma o mínimo da função custo fica como em:

\begin{equation}
\underset{\theta}{min}\;V(\theta)=V(\hat{\theta})=\frac{1}{2}\left [ y^Ty-y^T\varphi (\varphi ^T \varphi )^{-1}\varphi ^T y \right ]
\end{equation}

O método dos mínimos quadrados é simples de ser aplicado, mas tem o inconveniente de que para que não existam
erros de polarização na estimativa, a variável de regressão $\varphi(t)$ não pode estar correlacionada com o
distúrbio estocástico $\nu(t)$. Assume-se que o sistema real é dado por:

\begin{equation}
y(t)=\varphi^T(t)\theta_0+\nu(t)
\label{eq:si_par_etim_lsm_true_sys}
\end{equation}

A correlação entre os regressores $\varphi(t)$ e $\nu(t)$ será nulo se o ruido for branco, o que de
certa forma é bastante restritivo.

\begin{equation}
E(\varphi(t) \; \nu(t)) = 0
\label{eq:si_par_etim_iv_estim}
\end{equation}

A equação \eqref{eq:si_par_etim_iv_estim} é também conhecida como {\it{bias}} ou erro de polarização da estimativa. Este
valor é o quanto em média as estimativas $\hat{\theta}$ ficarão afastadas do valor real $\theta^*$. Obviamente esta não
é uma informação conhecida por parte do projetista do experimento de identificação.

Satisfeito somente se $\nu(t)$ for ruido branco. Esta desvantagem do método dos mínimos quadrados pode ser
visto como uma oportunidade para a introdução do método de variáveis instrumentais.
\cite{system_identification}

%===============================================================================
\subsection{Método das variáveis instrumentais}
\label{sec:si_par_estim_iv}
%===============================================================================
% bibliografia principal: aguirre e ljung

Como foi visto anteriormente o método dos mínimos quadrados é simples e fácil de ser aplicado mas carece
quando existe correlação entre o regressor $\varphi$ e o ruído estocástico $\nu$. Nesta seção será apresentado
uma breve discussão sobre um dos métodos que se propõem a sanar esta fraqueza do método dos mínimos quadrados:
método das vairáveis instrumentais.

Assume-se que $Z(t)$ é uma matriz $n\times n$ que possuem sinais não correlacionados com o 
distúrbio $\nu(t)$. O parâmetro $\theta$ deve obedecer a restrição da equação \eqref{eq:si_par_estim_iv_theta}:

\begin{equation}
\frac{1}{N}\sum_{t=1}^{N}Z(t)\varepsilon (t)=\frac{1}{N}\sum_{t=1}^{N}Z(t)\left [ y(t)-\varphi^T(t)\theta \right ]= 0
\label{eq:si_par_estim_iv_theta}
\end{equation}

Se a dimensão da matriz $Z(t)$ for a mesma dimensão de $\theta$ temos o estimador do método das 
variáveis instrumentais \eqref{eq:si_par_estim_iv}:

\begin{equation}
\hat{\theta}=\left [ \sum_{t=1}^{N}Z(t)\varphi^T(t) \right ]^{-1}\left [  \sum_{t=1}^{N}Z(t)y(t) \right ]
\label{eq:si_par_estim_iv}
\end{equation}

Os elementos da matriz $Z(t)$ são normalmente chamados de instrumentos. O estimador das variáveis instrumentais 
é uma generalização do estimador dos mínimos quadrados, quando $Z(t)=\varphi(t)$. \cite{system_identification}

O estimador de variáveis instrumentais evita a polarização garantido  que o vetor de erro seja não correlacionado
com as variáveis instrumentais. Esta condição e menos restritiva que a condição dos mínimos quadrados para que
não haja erro de polarização \eqref{eq:si_par_etim_iv_estim}. O valor a ser pago por isso envolve: \cite{aguirre}

\begin{enumerate}[(I)]
\item Escolha das variáveis instrumentais.
\item O estimador resultante é assintoticamente não polarizado, ao invés de ser apenas não polarizado. 
\end{enumerate}

Ao escolher as variáveis instrumentais é importante notar que a escolha não deve ser apenas para evitar 
a correlação entre o vetor de erro e os instrumentos. A razão para isso é que as variáveis instrumentais 
devem ser tão correlacionadas quanto possível com os regressores do modelo, caso contrário $Z(t)\varphi(t)^T$ 
seria próxima a singular e sua inversa muito mal condicionada. Portanto os instrumentos devem ser, idealmente, 
pouco correlacionados com o erro e muito correlacionados com os regressores do modelo. \cite{aguirre}

%===============================================================================
\subsection{Modelagem do ruído}
\label{sec:si_par_estim_noise_modeling}
%===============================================================================

