%===============================================================================
\section{Premissas para o sucesso do experimento de identificação}
\label{sec:sys_ident_experiments}
%===============================================================================

Em aplicações de engenharia, deseja-se que a solução de um problema seja única. Desta forma existem algumas
premissas que devem ser satisfeitas para que o processo de identificação consiga atingir seus objetivos, obtendo um
único vetor $\theta$ que consiga representar melhor o sistema real $\mathcal{S}$ de acordo com o critério de desempenho	
escolhido.

Devem ser levadas em consideração algumas características sobre o sinal de excitação do sistema e sobre a escolha da
classe de modelos que irá representar o sistema real $\mathcal{S}$, para que o processo de identificação possa ser único
e representativo, contendo o menor erro possível, além de que esta margem de erro seja conhecida.

%===============================================================================
\subsection{Persistência de Excitação}
\label{sec:si_data_persistently_excitation}
% most part of it came from ljung pg 412
%===============================================================================

Um sinal quasi-estacionário $u(t)$, com espectro $\Phi _u(\omega)$ é dito
{\it{persistentemente excitante de ordem n}} se, para todos os filtros de forma:

\begin{equation}
M_n(q)=m_1q^{-1}+...+m_nq^{-n}
\label{eq:si_data_persistence}
\end{equation}
a relação

\begin{equation}
\left | M_n(e^{i\omega}) \right |^2 \Phi_u(\omega)\equiv 0, \;\; \text{implica que}\; M_n(e^{i\omega}) \equiv 0
\label{eq:si_data_persistence_2}
\end{equation}

Outra caracterização pode ser dada em termos da função de covariância, onde $R_u(\tau)=u(t)$ é um
sinal quasi-estacionário, e $\bar{R}_n$ uma matriz $n\times n$ definida como:

\begin{equation}
\bar{R}_n=\begin{bmatrix}
R_u(0) & R_u(1) & ... & R_u(n-1)\\ 
R_u(1) & R_u(2) & ... & R_u(n-2)\\ 
\vdots & \vdots & \vdots & \vdots \\ 
R_u(n-1) & R_u(n-2) & ... & R_u(0)
\end{bmatrix}
\label{eq:si_data_persistently_rn}
\end{equation}

Então $u(t)$ é persistentemente excitante de ordem $n$ se e somente se $\bar{R}_n$ for não singular \cite{ljung}.

A partir da equação \eqref{eq:si_data_persistence_2} pode-se extrair interpretações mais explícitas.
Uma delas é que para que o sinal seja persistentemente excitante de ordem $n$, ele precisa ter $n$ componentes de
frequência distintas no intervalo $-\pi< \omega \le \pi$.

Se um sinal quasi-estacionário é filtrado por uma função de transferência estável, então o sinal resultante 
também é um sinal quasi-estacionário e desta forma se ${ \left| { M }_{ n }({ e }^{ j\omega  }) \right|  }^{ 2
}{ \Phi  }_{ u }(\omega )$ é o espectro do sinal $\varrho (t)={ M }_{ n }(q)u(t)$ então este sinal não perde sua
persistência de excitação se filtrado pelo filtro  ${ M }_{ n }(q)$.

Considere o somatório de senoides:
\begin{equation}
u(t)=\sum_{k=1}^{n}\mu_k \cos (\omega_kt), \;\; \omega_k \neq \omega_j, \;\; \omega_k \neq 0, \; \omega_k \neq \pi
\label{eq:si_data_persistently_sum_cos}
\end{equation}
cada uma possui duas linhas espectrais em $\pm \, \omega_k$, fazendo com que este sinal seja persistentemente excitante
de ordem $2n$.

%===============================================================================
\subsection{Experimentos Informativos}
% most part of it came from ljung pg 414
%===============================================================================

Na Seção \ref{sec:si_data_persistently_excitation} foi visto como caracterizar
sinais que são suficiente informativos. Considere um conjunto de modelos $\mathcal{M}$ para um sistema 
SISO descrito por \eqref{eq:si_intro_model} tendo a função de transferência $G(q,\theta)$ a
função racional:

\begin{equation}
G(q,\theta)=\frac{B(q,\theta)}{F(q,\theta)}=\frac{q^{n_k}(b_1+b_2q^{-1}+...+b_{nb}q^{-n_b+1})}{1+f_1q^{-1}+...+f_{n_f}q^{-nf}}
\label{eq:si_data_g_rational}
\end{equation}

Um experimento em malha aberta é informativo se a sua entrada for persistentemente excitante.
Observa-se que é necessário que a ordem de excitação seja igual ao número de parâmetros a
serem estimados \cite{ljung}. No caso da equação apresentada em \eqref{eq:si_data_g_rational} a ordem de excitação
necessária é $n_b+n_f$. Em \cite{gevers_bazanella2009} foram apresentadas as condições necessárias e suficientes para
informatividade em estruturas de modelos arbitrárias.

Garantir a persistência de excitação para um sinal utilizado na identificação de um sistema é garantir que
o sinal terá componentes de frequência suficientes para excitar o sistema ao ponto de ser possível observar sua dinâmica
de forma satisfatória. Inclui-se, desta forma, na identificação informações suficientes para que todos os
parâmetros da classe de modelos possam ser identificados.

%===============================================================================
\subsection{Escolha do modelo e sobre-modelagem}
\label{sec:si_exper_overfit}
%===============================================================================

A escolha de um conjunto de modelos $\mathcal{M}$ onde a ordem do modelo é maior do que a ordem do sistema real
$\mathcal{S}$ faz com que existam infinitas combinações de $\theta$, resultando em infinitos modelos dentro do conjunto
$\mathcal{M}$, que conseguem descrever exatamente o sistema $\mathcal{S}$.

Considere como exemplo o seguinte sistema real:

\begin{equation}
\mathcal{S}: \;\;\; G_0(q)=\frac{a}{q-b}, \;\;\; H_0(q)=\frac{1}{q-b}
\label{eq:si_exper_overfit_ex_s}
\end{equation}
e a estrutura de modelos:

\begin{equation}
\mathcal{M}: \;\;\; G(q, \theta)=\frac{\theta_1(q-\theta_2)}{(q-\theta_3)(q-\theta_4)}, \;\;\; H(q, \theta)=\frac{1}{q-\theta_5}
\label{eq:si_exper_overfit_ex_m}
\end{equation}

Observa-se que existem infinitos conjuntos de parâmetros $\theta$ que fazem com que a classe de modelos em
\eqref{eq:si_exper_overfit_ex_m} consiga representar o sistema real em \eqref{eq:si_exper_overfit_ex_s}:

\begin{equation}
\theta=\left [ \begin{matrix}
a & X & X & b & b
\end{matrix} \right ]
\label{eq:si_exper_overfit_ex_theta}
\end{equation}
ou 

\begin{equation}
\theta=\left [ \begin{matrix}
a & X & b & X & b
\end{matrix} \right ]
\nonumber
\end{equation}
com $X$ podendo assumir qualquer valor. Deve ficar claro que esta situação apresentada de sobre modelagem irá
apresentar erros com relação ao sistema real, no momento que houverem mínimas diferenças entre os valores estimados de
$X$ no numerador e $X$ no denominador.

A escolha de uma classe de modelos $\mathcal{M}$ é o ponto mais crucial para que o processo de identificação de sistemas
tenha sucesso. Esta escolha deve ser feita com base no entendimento do procedimento de identificação e das percepções e
conhecimentos que se tem sobre o sistema a ser identificado \cite{ljung}.

O preço ou custo de uma classe de modelos pode ser mensurado em alguns aspectos e a escolha da classe de modelos se dará
por alguma ponderação sobre estes critérios, que podem ser \cite{ljung}:

\begin{itemize}
  \item Flexibilidade: Usando classes de modelos que tenham boas capacidades de descrever tipos diferentes de sistemas.
  Flexibilidade pode ser obtida usando-se vários parâmetros ou alocando-os em ``posições estratégicas''.
  \item Parcimônia: Não usar desnecessariamente uma quantidade elevada de parâmetros.
  \item Complexidade do algoritmo: A complexidade de obter o erro de predição $\varepsilon (t, \theta)$ e as demais
  informações necessárias à identificação são fortemente correlacionadas com a escolha de $\mathcal{M}$ e a sua ordem.
  \item Propriedades da função critério. Dependendo do formato da curva, o algoritmo para encontrar o mínimo pode ser
  mais custoso no que diz respeito a iterações matemáticas.
  \item O uso pretendido do modelo.
\end{itemize}

O uso de classes de modelos com diversos parâmetros só deve ser utilizado se modelos com menos parâmetros não passarem
pelos testes de validação do modelo escolhido. Desta forma mantém-se a ideia de que quanto mais simples melhor,
garantindo a parcimônia da classe escolhida e conseguindo cumprir com o uso pretendido do sistema.

Uma das primeiras justificativas para o desenvolvimento de métodos para a escolha de classes de modelos é a
dificuldade em trabalhar com classes de modelos com muitos parâmetros, pelas complexidades adicionadas aos algoritmos
e as incertezas matemáticas inseridas. Além disso existe o problema destes modelos serem numericamente mal
condicionados além da convicção de que alguns parâmetros são redundantes e poderiam ser removidos do modelo (aplicando
algum algoritmo de simplificação de modelo). Um modelo com um número excessivo de parâmetros pode exibir dinâmicas que
não são observadas no sistema real. Desta forma não existe apenas o problema numérico para a identificação, mas também
um problema de dinâmica em utilizar um modelo sobre dimensionado \cite{aguirre_jacome}.

O procedimento que testa se a classe de modelos é simples e apropriada para descrever o sistema é aplicar alguma técnica
de redução à classe de modelos. Se a ordem da classe de modelos pode ser reduzida sem afetar as propriedades de entrada
e saída do sistema, então a classe de modelos original era desnecessariamente complexa \cite{ljung}.

Por fim, ao escolher uma classe de modelos para a identificação, deve-se levar em conta diversos pontos e informações.
Depois de escolhido o modelo, um processo de validação é indicado a ser executado. Este procedimento é simples e
consiste em algumas perguntas que o projetista do experimento de identificação deve fazer:

\begin{itemize}
  \item A classe de modelos escolhida consegue descrever suficientemente bem os dados observados?
  \item A classe de modelos é boa suficiente para meus objetivos?
  \item A classe de modelos descreve o sistema real ($\mathcal{S}$) ?
\end{itemize}

Se todas as perguntas forem justificadas, então o processo de escolha do modelo é satisfatório para o processo de
identificação.
