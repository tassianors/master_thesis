%===============================================================================
\section{Propriedades estatisticas da estimativa}
\label{sec:sys_ident_prop_estim}
%===============================================================================
% mains idea of this section:

%===============================================================================
\subsection{Incertezas nos parâmetros estimados}
\label{sec:si_par_estim_uncertanties}
%===============================================================================

O desejo principal para a estimativa de um sistema é que este não possua erros, ou ao menos que este erro, 
se existir, seja o menor possível. Para tanto é necessário caracterizar este tipo de informação do sistema.
Existem dois tipos principais de erro na estimativa de parâmetros. Um deles é o {\it{erro de variância}} e
outro é o {\it{erro de polarização}}.

Seja, $\theta^*$ o limite de convergência para a minimização do erro de predição:

\begin{equation}
\lim_{N \rightarrow \infty }\hat{\theta}_N = \theta^*
\label{eq:si_par_estim_under_theta}
\end{equation}

Sejam os vetores:

\begin{equation}
	Q(q)=\begin{bmatrix}
G_0(q) & H_0(q)
\end{bmatrix}^T
\nonumber
\end{equation}


\begin{equation}
\hat{Q}_N(q)=\begin{bmatrix}
G_0(q, \hat{\theta}_N) & H_0(q, \hat{\theta}_N)
\end{bmatrix}^T
\nonumber
\end{equation}

A qualidade da estimativa pode ser calculada em termos da diferença entre o processo real $Q_0(q)$ e o 
melhor sistema que o modelo pode atingir (quando a quantidade de dados é ilimitada ($N\rightarrow \infty$)) tem-se
então a estimativa do modelo $G_N(q)$.\cite{campestrini, solari}

\begin{equation}
\Delta Q_N(q) \equiv \hat{Q}_N-Q(q)
\label{eq:si_par_estim_under_diff}
\end{equation}

Define-se então:

\begin{equation}
Q^*(q) = \left [ G(q, \theta^*) \; H(q, \theta^*) \right ]^T
\label{eq:si_par_estim_under_q*}
\end{equation}

Entende-se por $Q^*(q)$ como a melhor aproximação que o método pode proporcionar (com $N \rightarrow \infty$) ou 
como sendo a média de todas as estimativas efetuadas.

Adicionando e subtraindo a \eqref{eq:si_par_estim_under_q*} na equação \eqref{eq:si_par_estim_under_diff}
chega-se a definição do erro de polarização e de variância \eqref{eq:si_par_estim_under_errors}.

\begin{equation}
\Delta Q_N(q) \equiv \underset{\text{Erro de variância}}{\underbrace{\hat{Q}_N-Q^*(q)}}+  \underset{\text{Erro de variância}}{\underbrace{Q^*(q)-Q(q)}}
\label{eq:si_par_estim_under_errors}
\end{equation}

A partir da \eqref{eq:si_par_estim_under_errors} compreende-se o erro de polarização como sendo a distância
entre a melhor aproximação possível e o valor real para o parâmetro. Já o erro de variância é a média que cada uma
das estimativas está distante do valor ótimo possível para a estimativa.

\begin{theorem}
Supondo um sistema linear $\mathcal{M}$ parametrizado com em \eqref{eq:si_par_estim_theorem_sys}
e  que os dados de entrada sejam suficientemente informativos.

\begin{equation}
\theta=\begin{bmatrix}
\rho \\ 
\eta 
\end{bmatrix},\;\;
G(q,\theta)=G(q,\rho), \;\;
H(q,\theta)=G(q,\eta)
\label{eq:si_par_estim_theorem_sys}
\end{equation}

Considerando que o sistema opera em malha aberta, ou seja:

\begin{equation}
u(t) \;e\; e_0(t)\text{ são independentes.}
\nonumber
\end{equation}

Seja:

\begin{equation}
\hat{\theta}_N=\begin{bmatrix}
\hat{\rho}_N \\ 
\hat{\eta}_N
\end{bmatrix}
\nonumber
\end{equation}

Obtido pelo método de predição apresentado %%achar a ref 
obtém-se:

\begin{equation}
\begin{matrix}
G(e^{j\omega},\hat{\theta}_N)\rightarrow G_0(e^{j\omega})\\ 
\text{quando:}\\
N\rightarrow \infty
\end{matrix}
\label{eq:si_par_estim_theorem_end}
\end{equation}
\end{theorem}

%===============================================================================
\subsubsection{Covariância nos parâmetros}
\label{sec:si_par_estim_uncertanties_covariance}
%===============================================================================

Um comum meio de medir a qualidade das estimativas é estudar suas propriedades assintóticas. Quando o valor
de $N$ (quantidade de dados) cresce muito, a estimativa pertencerá a alguma distribuição. As propriedades desta
irão determinar a qualidade das estimativas obtidas.\cite{jansson}

\begin{equation}
\begin{matrix}
\sqrt{N}(\hat{\theta}_N-\theta_0) \to \mathcal{N}(0,P) \;\; \text{quando} \;\; N\to \infty \\ \\
\lim_{N\to \infty}N\;E(\hat{\theta}_N-\theta_0)()\hat{\theta}_N-\theta_0)^T=P\\\\
P(\theta_0)=\lambda_0(E\left [ \psi (t,\theta_0)\psi^T(t,\theta_0) \right ])^{-1}\\ \\
\psi (t,\theta_0)=\frac{\partial }{\partial \theta}\hat{y}(t,\theta)\mid_{\theta=\theta_0}
\end{matrix}
\label{eq:si_par_estim_conv_def}
\end{equation}

Não é apenas o tamanho ($N$) do experimento que irá influenciar na qualidade da estimativa.
Na equação \eqref{eq:si_par_estim_cov_spectrum} apresenta-se o espectro onde $\Phi_u$ é o espectro da entrada $u(t)$, 
$\Phi_{ue}$ é o espectro cruzado entre a entrada e o erro $e_0$. Esta distribuição do espectro, $\Phi_{\chi 0}$
também influenciará na qualidade da estimativa, como pode ser visto no Lemma \ref{lemma:si_par_estim_covariance}.

\begin{equation}
\Phi_{\chi 0}=\begin{bmatrix}
\Phi_u & \Phi_{ue}\\ 
\Phi_{ue} & \lambda_0
\end{bmatrix}
\label{eq:si_par_estim_cov_spectrum}
\end{equation}

\begin{lemma}
A inversa da matriz de covariância, $P^{-1}(\theta_0)$, é uma função linear do espectro $\Phi_{\chi 0}$ dado por
\eqref{eq:si_par_estim_cov_lemma}.

\begin{equation}
P^{-1}(\theta_0)=\frac{1}{2\pi \lambda_0}\int_{-\pi}^{\pi}\mathcal{F}(\theta_0)
\Phi_{\chi_0}(\theta_0)\mathcal{F}^*(\theta_0) d \omega
\label{eq:si_par_estim_cov_lemma}
\end{equation}

Onde $\mathcal{F}(q, \theta_0)=\left [ \mathcal{F}_u(q, \theta_0) \;\;\;\mathcal{F}_e(q, \theta_0) \right ]$ e:

\begin{equation}
\mathcal{F}_u(\theta_0) = H^{-1}(\theta_0)\frac{\mathrm{d} G(\theta_0)}{\mathrm{d} \theta} 
\nonumber
\end{equation}

\begin{equation}
\mathcal{F}_e(\theta_0) = H^{-1}(\theta_0)\frac{\mathrm{d} H(\theta_0)}{\mathrm{d} \theta}
\nonumber
\end{equation}
\label{lemma:si_par_estim_covariance}
\end{lemma}

Como $P$ é a medida do tamanho do erro nos parâmetros, o Lemma \ref{lemma:si_par_estim_covariance} mostra
como este erro é relacionado com o espectro $\Phi_{\chi 0}$. O espectro cruzado $\Phi_{ue}$ é zero quando 
o sistema esta operando em laço aberto. \cite{jansson}

%===============================================================================
\subsubsection{Margens de confiança das estimativas}
\label{sec:si_par_estim_uncertanties_confidence_bounds}
%===============================================================================

A partir da distribuição assintótica normal em \eqref{eq:si_par_estim_conv_def} segue:

\begin{equation}
(\hat{\theta}_N-\theta_0)^T P^{-1}_{N}(\hat{\theta}_N-\theta_0)\rightarrow \chi^2(n)\;\; \text{quando}\; N\to \infty
\nonumber
\end{equation}

Com $P_N=P/N$ e onde \eqref{eq:si_par_estim_confidence_region} é a região de confiança, onde assintoticamente
inclui $\theta_0$ com probabilidade $\alpha$. Desta forma tem-se que as estimativas estarão centradas em $\theta_0$
e com probabilidade $\alpha$ estarão contidas em uma esfera definida por $P_N$ e $\chi_{\alpha}^2(N)$

\begin{equation}
U_\theta=\left \{ \theta \mid (\hat{\theta}_N-\theta_0)^T P^{-1}_{N}(\hat{\theta}_N-\theta_0) \le \chi^2_{\alpha}(n)  \right \}
\label{eq:si_par_estim_confidence_region}
\end{equation}

Na Figura (\ref{fig:si_covar_elipse}) é apresentado um exemplo de região de confiança para um $\chi$ de 95\%. O ponto em destaque
é a média de todas as estimativas e está localizado no centro da região de confiança.

\begin{figure}[htbp]
	\center
	\includegraphics[width=0.8\columnwidth]{figures/si_covar_elipse.eps}
	\caption{Estimativas de um sistema e a região de confiança para $\chi$ de 95\%}
	\label{fig:si_covar_elipse}
\end{figure}


