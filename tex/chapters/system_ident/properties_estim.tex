%===============================================================================
\section{Propriedades estatisticas da estimativa}
\label{sec:sys_ident_prop_estim}
%===============================================================================
% mains idea of this section:
Durante a identificação de um sistema, o tipo de sinal aplicado, o número de dados utilizados proporcionam resultados
diferentes para os esperimentos realizados. É importante entender o que e onde estes parametros afetam na resposta final
da identificação, para que se consiga evita-los ou ao menos entendelos e saber o quão confiável foi a estimativa gerada. 

As propriedades estatisticas das estimativas trazem consigo algumas informações extremamente úteis para a identificação
de sistemas. Nesta seção serão abordadas algumas destas caracteristicas e o que elas dizem, ou permitem dizer sobre a
estimativa dos parametros do sistema.

%===============================================================================
\subsection{Incertezas nos parâmetros estimados}
\label{sec:si_par_estim_uncertanties}
%===============================================================================

O desejo principal para a estimativa de um sistema é que este não possua erros, ou ao menos que este erro, 
se existir, seja o menor possível. Para tanto é necessário caracterizar este tipo de informação do sistema.
Existem dois tipos principais de erros na estimativa de parâmetros. Um deles é o {\it{erro de variância}} e
outro é o {\it{erro de polarização}}.

Seja, $\theta^*$ o limite de convergência para a minimização do erro de predição:

\begin{equation}
\lim_{N \rightarrow \infty }\hat{\theta}_N = \theta^*
\label{eq:si_par_estim_under_theta}
\end{equation}

Sejam os vetores:

\begin{equation}
Q(q)=\begin{bmatrix}
G_0(q) & H_0(q)
\end{bmatrix}^T
\nonumber
\end{equation}


\begin{equation}
\hat{Q}_N(q)=\begin{bmatrix}
G(q, \hat{\theta}_N) & H(q, \hat{\theta}_N)
\end{bmatrix}^T
\nonumber
\end{equation}

A qualidade da estimativa pode ser calculada em termos da diferença entre o processo real $Q_0(q)$ e o 
melhor sistema que o modelo pode atingir (quando a quantidade de dados é ilimitada ($N\rightarrow \infty$)) tem-se
então a estimativa do modelo $G_N(q)$.\cite{campestrini, solari}

\begin{equation}
\Delta Q_N(q) \equiv \hat{Q}_N-Q(q)
\label{eq:si_par_estim_under_diff}
\end{equation}

Define-se então:

\begin{equation}
Q^*(q) = \left [ G(q, \theta^*) \; H(q, \theta^*) \right ]^T
\label{eq:si_par_estim_under_q*}
\end{equation}

Entende-se por $Q^*(q)$ como a melhor aproximação que o método pode proporcionar (com $N \rightarrow \infty$) ou 
como sendo a média de todas as estimativas efetuadas.

Adicionando e subtraindo a \eqref{eq:si_par_estim_under_q*} na equação \eqref{eq:si_par_estim_under_diff}
chega-se a definição do erro de polarização e de variância \eqref{eq:si_par_estim_under_errors}.

\begin{equation}
\Delta Q_N(q) \equiv \underset{\text{Erro de variância}}{\underbrace{\hat{Q}_N(q)-Q^*(q)}}+  \underset{\text{Erro de
polarização}}{\underbrace{Q^*(q)-Q(q)}}
\label{eq:si_par_estim_under_errors}
\end{equation}

Onde $Q^*(q)=\left [ G(q, \theta^*) \;\;\; H(q, \theta^*)\right ]$.

A partir da \eqref{eq:si_par_estim_under_errors} compreende-se o erro de polarização como sendo a distância
entre a melhor aproximação possível e o valor real para o parâmetro. Já o erro de variância é a média que cada uma
das estimativas está distante do valor ótimo possível para a estimativa.

%===============================================================================
\subsubsection{Covariância nos parâmetros}
\label{sec:si_par_estim_uncertanties_covariance}
%===============================================================================

Um meio comum de medir a qualidade das estimativas é estudar suas propriedades assintóticas. Quando o valor
de $N$ (quantidade de dados) cresce muito, a estimativa pertencerá a alguma distribuição. As propriedades desta
irão determinar a qualidade das estimativas obtidas.\cite{jansson}

\begin{equation}
\begin{matrix}
\sqrt{N}(\hat{\theta}_N-\theta^*) \to \mathcal{N}(0,P) \;\; \text{quando} \;\; N\to \infty \\ \\
\lim_{N\to \infty}N\;E(\hat{\theta}_N-\theta^*)()\hat{\theta}_N-\theta^*)^T=P\\\\
P(\theta^*)=\lambda_0(E\left [ \psi (t,\theta^*)\psi^T(t,\theta^*) \right ])^{-1}\\ \\
\psi (t,\theta^*)=\frac{\partial }{\partial \theta}\hat{y}(t,\theta)\mid_{\theta=\theta^*}
\end{matrix}
\label{eq:si_par_estim_conv_def}
\end{equation}

Não é apenas o tamanho ($N$) do experimento que irá influenciar na qualidade da estimativa.
Na equação \eqref{eq:si_par_estim_cov_spectrum} apresenta-se o espectro onde $\Phi_u$ é o espectro da entrada $u(t)$, 
$\Phi_{ue}$ é o espectro cruzado entre a entrada e o erro $e_0$. Esta distribuição do espectro, $\Phi_{\chi 0}$
também influenciará na qualidade da estimativa, como pode ser visto no Lemma \ref{lemma:si_par_estim_covariance}.

\begin{equation}
\Phi_{\chi 0}=\begin{bmatrix}
\Phi_u & \Phi_{ue}\\ 
\Phi_{ue} & \lambda_0
\end{bmatrix}
\label{eq:si_par_estim_cov_spectrum}
\end{equation}

\begin{lemma}
A inversa da matriz de covariância, $P^{-1}(\theta^*)$, é uma função linear do espectro $\Phi_{\chi 0}$ dado por
\eqref{eq:si_par_estim_cov_lemma}.

\begin{equation}
P^{-1}(\theta^*)=\frac{1}{2\pi \lambda_0}\int_{-\pi}^{\pi}\mathcal{F}(\theta^*)
\Phi_{\chi_0}(\theta^*)\mathcal{F}^*(\theta^*) d \omega
\label{eq:si_par_estim_cov_lemma}
\end{equation}

Onde $\mathcal{F}(q, \theta^*)=\left [ \mathcal{F}_u(q, \theta^*) \;\;\;\mathcal{F}_e(q, \theta^*) \right ]$ e:

\begin{equation}
\mathcal{F}_u(\theta_0) = H^{-1}(\theta_0)\frac{\mathrm{d} G(\theta_0)}{\mathrm{d} \theta} 
\nonumber
\end{equation}

\begin{equation}
\mathcal{F}_e(\theta_0) = H^{-1}(\theta_0)\frac{\mathrm{d} H(\theta_0)}{\mathrm{d} \theta}
\nonumber
\end{equation}
\label{lemma:si_par_estim_covariance}
\end{lemma}

Como $P$ é a medida do tamanho do erro nos parâmetros, o Lemma \ref{lemma:si_par_estim_covariance} mostra
como este erro é relacionado com o espectro $\Phi_{\chi 0}$. O espectro cruzado $\Phi_{ue}$ é zero quando 
o sistema esta operando em laço aberto. \cite{jansson}

%===============================================================================
\subsubsection{Margens de confiança das estimativas}
\label{sec:si_par_estim_uncertanties_confidence_bounds}
%===============================================================================

A partir da distribuição assintótica normal em \eqref{eq:si_par_estim_conv_def} segue:

\begin{equation}
(\hat{\theta}_N-\theta_0)^T P^{-1}_{N}(\hat{\theta}_N-\theta_0)\rightarrow \chi^2(n)\;\; \text{quando}\; N\to \infty
\nonumber
\end{equation}

Com $P_N=P/N$ e onde \eqref{eq:si_par_estim_confidence_region} é a região de confiança, onde assintoticamente
inclui $\theta_0$ com probabilidade $\alpha$. Desta forma tem-se que as estimativas estarão centradas em
$\hat{\theta}_N$ e com probabilidade $\alpha$ estarão contidas em uma esfera definida por $P_N$ e $\chi_{\alpha}^2(N)$

\begin{equation}
U_\theta=\left \{ \theta \mid (\hat{\theta}_N-\theta^*)^T P^{-1}_{N}(\hat{\theta}_N-\theta^*) \le \chi^2_{\alpha}(n) \right \}
\label{eq:si_par_estim_confidence_region}
\end{equation}

Na Figura (\ref{fig:si_covar_elipse}) é apresentado um exemplo de região de confiança para um $\chi$ de 95\%. O ponto em destaque
é a média de todas as estimativas e está localizado no centro da região de confiança.

\begin{figure}[htbp]
	\center
	\includegraphics[width=0.8\columnwidth]{figures/si_covar_elipse.eps}
	\caption{Estimativas de um sistema e a região de confiança para $\chi$ de 95\%}
	\label{fig:si_covar_elipse}
\end{figure}


