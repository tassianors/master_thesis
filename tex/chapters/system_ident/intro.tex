%===============================================================================
\section{Definições}
\label{sec:sys_ident_intro}
%===============================================================================
% mains idea of this section: define witch systems willl we be managing: LTI TD SISO
% what are the 3 main elements of system identification: real system, model, an some criteria
% prediction error model comes here.

Identificação de sistemas possui uma vasta aplicabilidade em inúmeros ramos do conhecimento,
não é escopo deste trabalho enumerar todas as possibilidades de utilização desta ferramenta, nem tão pouco 
esmiuçar sua teoria. Serão aqui abordadas as principais características e princípios que compõem a teoria de 
identificação de sistemas lineares.

O principal objetivo da identificação de um sistema é encontrar um modelo matemático que melhor consiga
descrever o sistema real sob observação, nas características desejadas escolhidas.

Neste capítulo tem-se o interesse de estudar sismtemas lineares invariantes no tempo (LTI - {\it{linear time
invariant}}) de tempo discreto. Este tipo de sistema pode ser representado como:

\begin{equation}
y(t)=G_0(q)u(t)+H_0(q)e(t)
\label{eq:si_intro_system}
\end{equation}

Onde $G_0(q)$ é a função de transferência que descreve o comportamento da planta
real, usualmente desconhecida e a qual tem-se o intúito de identificar.
Análogamente $H_0(q)$ é a função de transferência que atua sobre o ruído branco
$e(t)$. $u(t)$ é o sinal de entrada aplicado sobre a planta e $y(t)$ é o sinal
de saída medido da planta.

Para identificar o sistema apresentado em \eqref{eq:si_intro_system} utiliza-se uma família de modelos
parametrizada por $\theta$ que genericamente pode ser representado como:

\begin{equation}
y(t)=G(q, \theta)u(t)+H(q, \theta)e(t)
\label{eq:si_intro_model}
\end{equation}

Onde as funções de transferência $G(q, \theta)$ e $H(q, \theta)$ podem ser definidos como a seguir:

\begin{equation}
G(q, \theta)=\sum_{k=1}^{\infty}g(k, \theta)q^{-k}
\nonumber
\end{equation}

\begin{equation}escolhida
H(q, \theta)=1+\sum_{k=1}^{\infty}h(k, \theta)q^{-k}
\nonumber
\end{equation}

A intenção da identificação de sistemas é encontrar um valor para o vetor $\theta$ que faça com que $G(q,
\theta)$ seja o mais próximo possível de $G_0(q)$. O vetor $\theta$ que faz com que estas duas funções de
transferências sejam iguais é denotado por $\theta^*$.

Outra definição que acompanha tudo que aqui será abordado é a definição de 	sinal quasi-estacionário:
Um sinal é dito quasi-estacionário se a média e a autocorrelação do mesmo convergem para um valor
finito quando o tamanho da amostra cresce, conforme definição a seguir:

\begin{defn}
\cite{ljung}

Um Sinal $s(t)$ é um processo quasi-estacionário se:
\begin{itemize}
	\item $\bar{E}\left [ s(t) \right ] = \mid m_s(t) \mid \le C, \;\forall t$;
	\item $\bar{E}\left [ s(t)s(r) \right ] = \mid R_s(t,s) \mid \le C, \;\forall t,r$;
	\item $\lim_{N \to \infty}\frac{1}{N}\sum_{t=1}^{N}R_s(t, t-\tau)=R_s(\tau), \; \forall \tau$,
\end{itemize}
Onde $m_s(t)$ é o valor médio do sinal $s(t)$ e $R_s(t,r)$ é a covariância do sinal $s$ nos
instantes $t$ e $r$.
\end{defn}

%===============================================================================
\subsection{Elementos da identificação}
\label{sec:sys_ident_elements}
%===============================================================================

Identificação de sistemas é dependente de três componentes básicas. Primeiro delas é o sistema real que se
está observando, definido pela letra $\mathcal{S}$ e é definido a partir de \eqref{eq:si_intro_system} como
abaixo:

\begin{equation}
\mathcal{S}:\;\; y(t)=G_0(q)u(t)+H_0(q)e(t)
\label{eq:si_intro_true_system}
\end{equation}

Outro ponto é a classe de modelos, denotada por $\mathcal{M}$:


\begin{equation}
\mathcal{M}: \;\;\left \{ G(q, \theta), h(q, \theta) | \theta \in D_{\mathcal{M}} \right \}
\label{eq:si_intro_model}
\end{equation}

%TODO> o que é DM

O terceiro componente é o critério de escolha que diz qual modelo dentro da classe é melhor que outro, em
outras palavras, qual modelo que melhor consegue representar o sistema real $\mathcal{S}$.

O critério mais utilizado é o de erro de predição. 

Preditores são equações que predizem qual será o próximo valor de saída do sistema
baseado na família do modelo e nos valores de dados coletados até aquele momento.
Os sinais $y(t)$ e $u(t)$ são os sinais da saída e entrada medidas do sistema real enquanto que o sinal
$\hat{y}(t)$ é o sinal de saída do preditor. A diferênça entre o valor do preditor e o valor do sistema real,
é conhecido como erro de predição:

\begin{equation}
\varepsilon(t)=y(t) - \hat{y}(t, \theta)
\label{eq:si_estim_prediction_error}
\end{equation}

A Figura (\ref{fig:si_estim_pem}) apresenta um diagrama de blocos de como é organizado o método do erro de
predição. Existe um processo que gostaria de ser estimado, para isso escolhe-se uma classe de modelos onde os
parametros a serem ajustados são $\theta$. O preditor é ajustado, baseado nas diferentes possíbilidades de
escolha de $\theta$, este ajuste é feito baseado no erro entre o sistema real ($y(t)$) e a saída do preditor
$\hat{y}(t, \theta)$.


\begin{figure}[htbp]
\center
%\scalebox{1} % Change this value to rescale the drawing.
%{
\begin{pspicture}(0,-2.6)(10.859062,2.6)
\psframe[linewidth=0.04,dimen=outer](4.2,2.6)(1.8,1.4)
\psframe[linewidth=0.04,dimen=outer](5.4,0.2)(3.0,-1.0)
\pscircle[linewidth=0.04,dimen=outer](8.2,1.0){0.4}
\psframe[linewidth=0.04,dimen=outer](8.6,-1.4)(5.6,-2.6)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<-}(1.8,2.0)(0.0,2.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(4.2,2.0)(10.0,2.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<-}(8.2,1.4)(8.2,2.0)
\psline[linewidth=0.04cm](5.4,-0.4)(8.2,-0.4)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(8.2,-0.4)(8.2,0.6)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<-}(8.6,-2.0)(9.2,-2.0)
\psline[linewidth=0.04cm](9.2,-2.0)(9.2,1.0)
\psline[linewidth=0.04cm](9.2,1.0)(8.6,1.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<-}(4.0,-1.0)(4.0,-2.0)
\psline[linewidth=0.04cm](5.6,-2.0)(4.0,-2.0)
\psline[linewidth=0.04cm](1.2,2.0)(1.2,-0.6)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<-}(3.0,-0.2)(2.0,-0.2)
\psline[linewidth=0.04cm](2.0,-0.2)(2.0,0.8)
\psline[linewidth=0.04cm](2.0,0.8)(5.0,0.8)
\psline[linewidth=0.04cm](5.0,0.8)(5.0,2.0)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<-}(3.0,-0.6)(1.2,-0.6)
\usefont{T1}{ptm}{m}{n}
\rput(2.9426563,2.11){Processo}
\usefont{T1}{ptm}{m}{n}
\rput(4.2964063,-0.29){Preditor}
\usefont{T1}{ptm}{m}{n}
\rput(7.1589065,-1.65){Algoritmo}
\usefont{T1}{ptm}{m}{n}
\rput(7.177656,-1.95){para minimizar}
\usefont{T1}{ptm}{m}{n}
\rput(7.140625,-2.33){f($\varepsilon(t,\theta)$)}
\usefont{T1}{ptm}{m}{n}
\rput(8.194531,0.99){$\sum$}
\usefont{T1}{ptm}{m}{n}
\rput(7.9126563,1.51){+}
\usefont{T1}{ptm}{m}{n}
\rput(7.847344,0.51){-}
\usefont{T1}{ptm}{m}{n}
\rput(9.694531,1.31){$\varepsilon(t,\theta)$}
\usefont{T1}{ptm}{m}{n}
\rput(6.514531,2.31){$y(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(0.71453124,2.31){$u(t)$}
\usefont{T1}{ptm}{m}{n}
\rput(7.114531,-0.09){$\hat{y}(t, \theta)$}
\usefont{T1}{ptm}{m}{n}
\rput(4.2632813,-0.69){Ajustável ($\theta$)}
\end{pspicture} 
%}
\caption{Diagrama de blocos para o método do erro de predição}
\label{fig:si_estim_pem}
\end{figure}

Considerando o sistema linear:

\begin{equation}
y(t)=G(q^{-1}, \theta)u(t)+H(q^{-1}, \theta)e(t)
\label{eq:si_par_estim_system}
\end{equation}

Assumindo que $G(0, \theta)=0$, $H(0,\theta)=I$ e que $H^{-1}(q^{-1}, \theta)$ e $H^{-1}(q^{-1},\theta)
G(q^{-1},\theta)$ são assisntóticamente estáveis, se $u(t)$ e $e(p)$ para $p<t$ não forem correlacionados
então o preditor ótimo pode ser apresentado como: \cite{system_identification}

\begin{equation}
\hat{y}(t|t-1, \theta)= H^{-1}(q^{-1}, \theta)G(q^{-1}, \theta)u(t)+\left \{ I-H^{-1}(q^{-1}, \theta) \right
\}y(t)
\label{eq:si_par_estim_predictor}
\end{equation}

\begin{equation}
\varepsilon (t,\theta)=e(t)=H^{-1}(q^{-1}, \theta)\left \{ y(t)-G(q^{-1}, \theta)u(t) \right \}
\nonumber
\end{equation}


Como já foi comentado o critério mais utilizado para elencar qual é o melhor modelo dentro da classe dentre os
infinitos possíveis é definida como :

\begin{equation}
V(\theta)=\frac{1}{2}\sum_{t=1}^{N}\varepsilon ^2(t)=\frac{1}{2}\varepsilon^T\varepsilon=\frac{1}{2}\left \| \varepsilon \right \|
\label{eq:si_obj_etim_lsm_v}
\end{equation}

 




